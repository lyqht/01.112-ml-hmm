{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning Design Project\n",
    "\n",
    "Team members: \n",
    "- Andri Setiawan Susanto\n",
    "- Eldon Lim \n",
    "- Tey Siew Wen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Already completed individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emissionPara(xy,y):\n",
    "    e_x_y= xy/y\n",
    "    \n",
    "    return e_x_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "1. Make a modified training set by replacing those words that appear $<k$ times in the training set with a special word token `#UNK#` before training.\n",
    "2. During testing phase, ifaworddoesnot appear in the modified training set, we also replace that wordwith `#UNK#`.\n",
    "3. Compute Emission Paramters with the function in (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "replaceWord = \"#UNK#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training(data,k):\n",
    "    global replaceWord\n",
    "    \n",
    "    start = time.process_time()   \n",
    "    \n",
    "    df= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    # dropping null value columns to avoid errors \n",
    "    x_dic = {}\n",
    "\n",
    "    # new data frame with split value columns \n",
    "    new = df[\"original\"].str.split(\" \", n=1,expand=True) \n",
    "\n",
    "    # making separate first name column from new data frame \n",
    "    df[\"x\"]= new[0] \n",
    "\n",
    "    # making separate last name column from new data frame \n",
    "    df[\"y\"]= new[1] \n",
    "\n",
    "    # df display \n",
    "    uniqueX, uniqueCountX= np.unique(df['x'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueX)):\n",
    "        x_dic[uniqueX[i]] = uniqueCountX[i]\n",
    "\n",
    "    for i, text in enumerate(df['x']):\n",
    "        if x_dic[text] < k:\n",
    "            df['x'][i] = replaceWord\n",
    "            df['original'][i]=df['original'][i].replace(text,replaceWord, 1)\n",
    "    y_dic={}\n",
    "    uniqueY, uniqueCountY= np.unique(df['y'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueY)):\n",
    "        y_dic[uniqueY[i]] = uniqueCountY[i]\n",
    "        \n",
    "    xy_dic = {}\n",
    "    df1= df.copy()\n",
    "    # Get a tuple of unique values & their count from a numpy array\n",
    "    df1.dropna(inplace = True) \n",
    "    uniqueXY, uniqueCountXY= np.unique(df1['original'].astype(str),return_counts=True)\n",
    "\n",
    "    for i in range(len(uniqueXY)):\n",
    "        xy_dic[uniqueXY[i]] = uniqueCountXY[i]\n",
    "    # print('Unique Values : ', uniqueValues)\n",
    "    \n",
    "    # print('Count of Unique Values : ', uniqueCount)\n",
    "    dft = pd.DataFrame([uniqueXY,uniqueCountXY]).T\n",
    "    dft=dft.rename({0:'x_y',1:'count_x_y'},axis='columns')\n",
    "    \n",
    "    dft['count_y']=0\n",
    "    for i,text in enumerate(dft['x_y']):\n",
    "        data = text.split(\" \")\n",
    "        dft['count_y'][i]=y_dic[data[1]]\n",
    "        \n",
    "    dft['emission']=emissionPara(dft['count_x_y'], dft['count_y'])\n",
    "    \n",
    "    dft1 = dft.copy()\n",
    "\n",
    "    # new data frame with split value columns \n",
    "    new = dft1[\"x_y\"].str.split(\" \", n=1,expand=True) \n",
    "\n",
    "    # making separate first name column from new data frame \n",
    "    dft1[\"x\"]= new[0] \n",
    "\n",
    "    # making separate last name column from new data frame \n",
    "    dft1[\"y\"]= new[1] \n",
    "    \n",
    "    xy_pred_dic = {}\n",
    "\n",
    "    for word in dft1['x']:\n",
    "        index = pd.Series.idxmax((dft1.loc[dft1['x'] == word]['emission']).astype(float))\n",
    "        xy_pred_dic[word]=dft1['y'][index] \n",
    "    print(\"Time taken for train data: \", time.process_time() - start)\n",
    "    return xy_pred_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(data,k):\n",
    "    global replaceWord\n",
    "    \n",
    "    start = time.process_time()   \n",
    "\n",
    "    testdf1= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    testdf= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "\n",
    "    x_dic = {}\n",
    "\n",
    "    uniqueX, uniqueCountX= np.unique(testdf1['original'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueX)):\n",
    "        x_dic[uniqueX[i]] = uniqueCountX[i]\n",
    "\n",
    "    testdf['modified']=''\n",
    "#     print(testdf)\n",
    "    for i, text in enumerate(testdf['original']):\n",
    "    #         df['x'][i] = replaceWord\n",
    "        try:\n",
    "            if text not in xy_pred_dic:\n",
    "            \n",
    "                testdf['modified'][i]=testdf['original'][i].replace(text,replaceWord)\n",
    "            else:\n",
    "                testdf['modified'][i]=testdf['original'][i]\n",
    "        except:\n",
    "            continue\n",
    "    testdf['predict_label']=''\n",
    "    for index, word in enumerate(testdf['modified']):\n",
    "#     print(word)\n",
    "        try:\n",
    "            testdf['predict_label'][index]= xy_pred_dic[word]\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Time taken for test data: \",time.process_time() - start)\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the four datasets EN, AL, CN, and SG, learn these parameters with `train`, and evaluate your\n",
    "system on the development set `dev.in` for each of the dataset. Write your output to `dev.p2.out`\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in `dev.out`\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis for data folder  AL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for train data:  26.46875\n",
      "Time taken for test data:  6.3125\n",
      "     result\n",
      "0  杭 B-CITY\n",
      "1  州 I-CITY\n",
      "2  市 I-CITY\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  EN\n",
      "Time taken for train data:  58.296875\n",
      "Time taken for test data:  16.53125\n",
      "         result\n",
      "0      HBO B-NP\n",
      "1      has B-VP\n",
      "2  close B-ADJP\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  CN\n",
      "Time taken for train data:  104.453125\n",
      "Time taken for test data:  14.046875\n",
      "             result\n",
      "0      一 I-negative\n",
      "1  #UNK# B-negative\n",
      "2  #UNK# B-negative\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  SG\n",
      "Time taken for train data:  416.0\n",
      "Time taken for test data:  42.734375\n",
      "               result\n",
      "0     Tour B-positive\n",
      "1  Scotland B-neutral\n",
      "2         followers O\n",
      "Writing the final result to dev.out...\n"
     ]
    }
   ],
   "source": [
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in data_folders:\n",
    "    print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "    test_result = \"./data/{}/dev.out\".format(x)\n",
    "    \n",
    "    xy_pred_dic = preprocess_training(train_data, k)\n",
    "    testdf = preprocess_test(test_data,k)\n",
    "    \n",
    "    testresultdf = pd.read_csv(test_result, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    new = testresultdf[\"original\"].str.split(\" \", n=1,expand=True) \n",
    "\n",
    "    # making separate first name column from new data frame \n",
    "    testresultdf[\"x\"]= new[0] \n",
    "\n",
    "    # making separate last name column from new data frame \n",
    "    testresultdf[\"y\"]= new[1]\n",
    "    final = pd.DataFrame()\n",
    "    \n",
    "    final['result'] = testdf['modified'] + ' ' + testdf['predict_label']\n",
    "    print(final.head(3))\n",
    "    \n",
    "    print(\"Writing the final result to dev.out...\")\n",
    "    f = open('./output/{}/dev.p2.out'.format(x) ,'w')\n",
    "    for word in final['result']:\n",
    "        f.write(word + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that estimates the transition parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-7-a4c85c9afcd9>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-a4c85c9afcd9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def transitionPara(seq):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
