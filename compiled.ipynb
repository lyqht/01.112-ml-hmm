{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning Design Project\n",
    "\n",
    "## About the Project\n",
    "\n",
    "We have 4 datasets in the `/data` folder. For each dataset, there is: \n",
    "- a labelled training set train, \n",
    "- an unlabelled development set `dev.in`\n",
    "- a labelled development set `dev.out` \n",
    "\n",
    "The labelled data has the format of: `token` `\\t` `tag`\n",
    "- one token per line\n",
    "- token and tag separated by tab \n",
    "- single empty lines that separates sentences\n",
    "\n",
    "For the labels, they are slightly different for different datasets.\n",
    "- SG, CN (Entity):\n",
    "    - B-*: Beginning of entity\n",
    "    - I-*: Inside of entity\n",
    "    - O: Outside of any entity\n",
    "- EN, AL (Phrase):\n",
    "    - B-VP: Beginning of Verb Phrase\n",
    "    - I-VP: Inside of Verb Phrase\n",
    "    - *-NP: Noun Phrase\n",
    "    - *PP: Propositional Phrase\n",
    "    - O: Outside of any phrase\n",
    "\n",
    "*Goal*: Build sequence labelling systems from training data (x) and use it to predict tag sequences for new sentences (y).\n",
    "\n",
    "## Team members \n",
    "- Andri Setiawan Susanto\n",
    "- Eldon Lim \n",
    "- Tey Siew Wen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Already completed individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emissionPara(xy,y):\n",
    "    e_x_y= xy/y\n",
    "    \n",
    "    return e_x_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "1. Make a modified training set by replacing those words that appear $<k$ times in the training set with a special word token `#UNK#` before training.\n",
    "2. During testing phase, ifaworddoesnot appear in the modified training set, we also replace that wordwith `#UNK#`.\n",
    "3. Compute Emission Paramters with the function in (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "replaceWord = \"#UNK#\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_columns(df_column):\n",
    "    new = df_column.str.split(\" \", n=1, expand=True)\n",
    "    return new[0], new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training(data,k):\n",
    "    global replaceWord\n",
    "    \n",
    "    start = time.process_time()   \n",
    "    x_dic = {}\n",
    "    \n",
    "    # dropping null value columns e.g. index_col to avoid errors \n",
    "    df= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    \n",
    "    # new data frame with split value columns \n",
    "    df[\"x\"], df[\"y\"] = split_into_columns(df[\"original\"])\n",
    "\n",
    "    # df display: record x value and replace y values with replaceWord when necessary, in respective dictionaries\n",
    "    uniqueX, uniqueCountX= np.unique(df['x'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueX)):\n",
    "        x_dic[uniqueX[i]] = uniqueCountX[i]\n",
    "\n",
    "    for i, text in enumerate(df['x']):\n",
    "        if x_dic[text] < k:\n",
    "            df['x'][i] = replaceWord\n",
    "            df['original'][i]=df['original'][i].replace(text,replaceWord, 1)\n",
    "    \n",
    "    y_dic={}\n",
    "    \n",
    "    uniqueY, uniqueCountY= np.unique(df['y'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueY)):\n",
    "        y_dic[uniqueY[i]] = uniqueCountY[i]\n",
    "        \n",
    "    xy_dic = {}\n",
    "    df1= df.copy()\n",
    "    \n",
    "    # Get a tuple of unique values & their count from a numpy array\n",
    "    df1.dropna(inplace = True) \n",
    "    uniqueXY, uniqueCountXY= np.unique(df1['original'].astype(str),return_counts=True)\n",
    "\n",
    "    for i in range(len(uniqueXY)):\n",
    "        xy_dic[uniqueXY[i]] = uniqueCountXY[i]\n",
    "    # print('Unique Values : ', uniqueValues)\n",
    "    \n",
    "    # print('Count of Unique Values : ', uniqueCount)\n",
    "    dft = pd.DataFrame([uniqueXY,uniqueCountXY]).T\n",
    "    dft=dft.rename({0:'x_y',1:'count_x_y'},axis='columns')\n",
    "    \n",
    "    dft['count_y']=0\n",
    "    for i,text in enumerate(dft['x_y']):\n",
    "        data = text.split(\" \")\n",
    "        dft['count_y'][i]=y_dic[data[1]]\n",
    "        \n",
    "    dft['emission']=emissionPara(dft['count_x_y'], dft['count_y'])\n",
    "    \n",
    "    # new data frame with split value columns \n",
    "    dft1 = dft.copy()\n",
    "    dft1[\"x\"], dft1[\"y\"] = split_into_columns(dft1[\"x_y\"])\n",
    "    \n",
    "    xy_pred_dic = {}\n",
    "\n",
    "    for word in dft1['x']:\n",
    "        index = pd.Series.idxmax((dft1.loc[dft1['x'] == word]['emission']).astype(float))\n",
    "        xy_pred_dic[word]=dft1['y'][index] \n",
    "    print(\"Time taken for train data: \", time.process_time() - start)\n",
    "    return xy_pred_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(data,k):\n",
    "    global replaceWord\n",
    "    \n",
    "    start = time.process_time()   \n",
    "\n",
    "    testdf1= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    testdf= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "\n",
    "    x_dic = {}\n",
    "\n",
    "    uniqueX, uniqueCountX= np.unique(testdf1['original'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueX)):\n",
    "        x_dic[uniqueX[i]] = uniqueCountX[i]\n",
    "\n",
    "    testdf['modified']=''\n",
    "#     print(testdf)\n",
    "    for i, text in enumerate(testdf['original']):\n",
    "    #         df['x'][i] = replaceWord\n",
    "        try:\n",
    "            if text not in xy_pred_dic:\n",
    "            \n",
    "                testdf['modified'][i]=testdf['original'][i].replace(text,replaceWord)\n",
    "            else:\n",
    "                testdf['modified'][i]=testdf['original'][i]\n",
    "        except:\n",
    "            continue\n",
    "    testdf['predict_label']=''\n",
    "    for index, word in enumerate(testdf['modified']):\n",
    "#     print(word)\n",
    "        try:\n",
    "            testdf['predict_label'][index]= xy_pred_dic[word]\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Time taken for test data: \",time.process_time() - start)\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the four datasets EN, AL, CN, and SG, learn these parameters with `train`, and evaluate your\n",
    "system on the development set `dev.in` for each of the dataset. Write your output to `dev.p2.out`\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in `dev.out`\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis for data folder  AL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for train data:  59.0\n",
      "Time taken for test data:  14.984375\n",
      "     result\n",
      "0  杭 B-CITY\n",
      "1  州 I-CITY\n",
      "2  市 I-CITY\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  EN\n",
      "Time taken for train data:  100.0\n",
      "Time taken for test data:  16.671875\n",
      "         result\n",
      "0      HBO B-NP\n",
      "1      has B-VP\n",
      "2  close B-ADJP\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  CN\n",
      "Time taken for train data:  121.1875\n",
      "Time taken for test data:  14.296875\n",
      "             result\n",
      "0      一 I-negative\n",
      "1  #UNK# B-negative\n",
      "2  #UNK# B-negative\n",
      "Writing the final result to dev.out...\n",
      "Performing sentiment analysis for data folder  SG\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-14a80192747f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/{}/dev.out\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mxy_pred_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtestdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-334bd44f53d2>\u001b[0m in \u001b[0;36mpreprocess_training\u001b[0;34m(data, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplaceWord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplaceWord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3346\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m                     \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[1;32m   3304\u001b[0m         \"\"\"\n\u001b[0;32m-> 3305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in data_folders:\n",
    "    print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "    test_result = \"./data/{}/dev.out\".format(x)\n",
    "    \n",
    "    xy_pred_dic = preprocess_training(train_data, k)\n",
    "    testdf = preprocess_test(test_data,k)\n",
    "    \n",
    "    testresultdf = pd.read_csv(test_result, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    new = testresultdf[\"original\"].str.split(\" \", n=1,expand=True) \n",
    "\n",
    "    # making separate first name column from new data frame \n",
    "    testresultdf[\"x\"]= new[0] \n",
    "\n",
    "    # making separate last name column from new data frame \n",
    "    testresultdf[\"y\"]= new[1]\n",
    "    final = pd.DataFrame()\n",
    "    \n",
    "    final['result'] = testdf['modified'] + ' ' + testdf['predict_label']\n",
    "    print(final.head(3))\n",
    "    \n",
    "    print(\"Writing the final result to dev.out...\")\n",
    "    f = open('./output/{}/dev.p2.out'.format(x) ,'w')\n",
    "    for word in final['result']:\n",
    "        f.write(word + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that estimates the transition parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('B-NP', 'I-NP'): 0.5928542665739284,\n",
       " ('I-NP', 'B-VP'): 0.40335122111488336,\n",
       " ('B-VP', 'B-ADVP'): 0.15975336322869954,\n",
       " ('B-ADVP', 'B-ADJP'): 0.03367579908675799,\n",
       " ('B-ADJP', 'I-ADJP'): 0.8521739130434782,\n",
       " ('I-ADJP', 'I-ADJP'): 0.14782608695652175,\n",
       " ('I-ADJP', 'B-PP'): 0.008917405252569191,\n",
       " ('B-PP', 'B-NP'): 0.3606813762786372,\n",
       " ('I-NP', 'B-PP'): 0.4646838127344897,\n",
       " ('I-NP', 'O'): 0.3945027009850651,\n",
       " ('O', 'O'): 0.36190022243406417,\n",
       " ('O', 'B-ADJP'): 0.13356164383561644,\n",
       " ('B-NP', 'B-VP'): 0.33753148614609574,\n",
       " ('B-VP', 'B-PP'): 0.09803708335598935,\n",
       " ('I-NP', 'I-NP'): 0.4071457334260717,\n",
       " ('O', 'B-NP'): 0.27912334094175334,\n",
       " ('B-VP', 'B-SBAR'): 0.2459189046866772,\n",
       " ('B-SBAR', 'B-NP'): 0.035019866429960265,\n",
       " ('B-VP', 'B-NP'): 0.13325302223349395,\n",
       " ('B-VP', 'O'): 0.039116619002224344,\n",
       " ('I-NP', 'B-NP'): 0.05558373488883253,\n",
       " ('B-ADVP', 'B-PP'): 0.03305964874123212,\n",
       " ('B-VP', 'I-VP'): 0.6720472440944882,\n",
       " ('I-VP', 'B-NP'): 0.07631667934736665,\n",
       " ('O', 'B-VP'): 0.1581425911729274,\n",
       " ('I-VP', 'I-VP'): 0.3279527559055118,\n",
       " ('B-NP', 'O'): 0.12170320940578329,\n",
       " ('B-NP', 'B-PP'): 0.14925778913599044,\n",
       " ('I-VP', 'B-PP'): 0.08194225436354739,\n",
       " ('B-PP', 'B-PP'): 0.01875917568375836,\n",
       " ('B-NP', 'B-NP'): 0.029334685941330627,\n",
       " ('I-NP', 'B-SBAR'): 0.1837809373354397,\n",
       " ('B-SBAR', 'B-VP'): 0.0039973715912824444,\n",
       " ('B-NP', 'B-ADVP'): 0.13004484304932734,\n",
       " ('B-ADVP', 'B-NP'): 0.015893143968213713,\n",
       " ('B-ADVP', 'I-ADVP'): 0.8539944903581267,\n",
       " ('I-ADVP', 'B-NP'): 0.001437145997125708,\n",
       " ('O', 'B-PP'): 0.11016257952259258,\n",
       " ('I-VP', 'B-SBAR'): 0.07056345444971038,\n",
       " ('I-VP', 'B-ADVP'): 0.1070627802690583,\n",
       " ('B-ADVP', 'O'): 0.03006037496027963,\n",
       " ('I-NP', 'B-ADVP'): 0.23598654708520178,\n",
       " ('I-ADVP', 'B-ADVP'): 0.003082959641255605,\n",
       " ('I-VP', 'O'): 0.01830314585319352,\n",
       " ('B-VP', 'B-PRT'): 0.4358974358974359,\n",
       " ('B-PRT', 'B-NP'): 0.005008876489982247,\n",
       " ('B-ADVP', 'B-VP'): 0.042164056510787425,\n",
       " ('O', 'B-ADVP'): 0.3102578475336323,\n",
       " ('B-PP', 'B-VP'): 0.02677691381009747,\n",
       " ('B-NP', 'B-ADJP'): 0.0867579908675799,\n",
       " ('B-ADJP', 'B-PP'): 0.02327225273231472,\n",
       " ('I-ADVP', 'O'): 0.0037813790911979664,\n",
       " ('B-VP', 'B-VP'): 0.007282882488226919,\n",
       " ('O', 'B-SBAR'): 0.2927856766719326,\n",
       " ('I-ADJP', 'B-NP'): 0.001098993997802012,\n",
       " ('B-NP', 'B-SBAR'): 0.08478146392838336,\n",
       " ('B-VP', 'B-ADJP'): 0.408675799086758,\n",
       " ('B-ADJP', 'B-VP'): 0.010623151900120469,\n",
       " ('I-NP', 'B-ADJP'): 0.1278538812785388,\n",
       " ('B-ADJP', 'O'): 0.014299332697807437,\n",
       " ('B-ADJP', 'B-NP'): 0.001923239496153521,\n",
       " ('B-PP', 'O'): 0.004988878296790594,\n",
       " ('B-ADVP', 'B-SBAR'): 0.030542390731964193,\n",
       " ('I-VP', 'B-VP'): 0.004599715255722264,\n",
       " ('I-ADJP', 'O'): 0.00584683825865904,\n",
       " ('B-PP', 'I-PP'): 0.9282511210762332,\n",
       " ('I-PP', 'B-NP'): 0.003698537492602925,\n",
       " ('B-ADVP', 'B-ADVP'): 0.017376681614349777,\n",
       " ('I-PP', 'B-VP'): 0.00038330960464352207,\n",
       " ('I-ADJP', 'B-SBAR'): 0.018430753027909426,\n",
       " ('B-ADJP', 'B-ADVP'): 0.007847533632286996,\n",
       " ('B-PP', 'B-ADJP'): 0.0273972602739726,\n",
       " ('B-PRT', 'B-PP'): 0.00614430971670926,\n",
       " ('I-ADVP', 'B-PP'): 0.003044967647218748,\n",
       " ('I-VP', 'B-ADJP'): 0.16837899543378995,\n",
       " ('I-ADVP', 'I-ADVP'): 0.14600550964187328,\n",
       " ('I-VP', 'B-PRT'): 0.5064102564102564,\n",
       " ('B-ADJP', 'B-SBAR'): 0.03528172722485519,\n",
       " ('O', 'B-CONJP'): 0.5510204081632653,\n",
       " ('B-CONJP', 'I-CONJP'): 0.71875,\n",
       " ('I-CONJP', 'B-NP'): 0.000591765998816468,\n",
       " ('B-SBAR', 'B-PP'): 0.0014681094013376107,\n",
       " ('B-NP', 'B-PRT'): 0.03632478632478633,\n",
       " ('I-ADVP', 'B-SBAR'): 0.015271195365982097,\n",
       " ('B-PRT', 'B-ADVP'): 0.003923766816143498,\n",
       " ('B-PRT', 'O'): 0.0023514458214172226,\n",
       " ('O', 'B-INTJ'): 0.9230769230769231,\n",
       " ('B-INTJ', 'I-INTJ'): 0.7142857142857143,\n",
       " ('I-INTJ', 'O'): 0.00015888147442008263,\n",
       " ('I-PP', 'B-ADJP'): 0.0005707762557077625,\n",
       " ('B-INTJ', 'O'): 0.0005084207181442644,\n",
       " ('B-SBAR', 'B-SBAR'): 0.00842548709847288,\n",
       " ('I-PP', 'B-PP'): 0.000761241911804687,\n",
       " ('I-ADVP', 'B-VP'): 0.001149928813930566,\n",
       " ('B-PP', 'B-ADVP'): 0.017096412556053812,\n",
       " ('B-SBAR', 'O'): 0.0017159199237368923,\n",
       " ('B-SBAR', 'B-ADVP'): 0.00476457399103139,\n",
       " ('B-INTJ', 'B-VP'): 0.00010951702989814916,\n",
       " ('I-PP', 'O'): 0.00028598665395614874,\n",
       " ('I-ADJP', 'B-VP'): 0.002190340597962983,\n",
       " ('B-SBAR', 'I-SBAR'): 1.0,\n",
       " ('I-SBAR', 'B-NP'): 0.000972186998055626,\n",
       " ('B-PP', 'B-SBAR'): 0.009478672985781991,\n",
       " ('I-NP', 'B-PRT'): 0.014957264957264958,\n",
       " ('I-CONJP', 'I-CONJP'): 0.28125,\n",
       " ('I-CONJP', 'B-PP'): 0.0003806209559023435,\n",
       " ('I-ADJP', 'B-ADVP'): 0.002242152466367713,\n",
       " ('B-PRT', 'B-VP'): 0.0010951702989814916,\n",
       " ('B-PRT', 'B-SBAR'): 0.004739336492890996,\n",
       " ('I-PP', 'I-PP'): 0.07174887892376682,\n",
       " ('B-VP', 'B-CONJP'): 0.061224489795918366,\n",
       " ('I-CONJP', 'B-VP'): 0.0005475851494907458,\n",
       " ('B-SBAR', 'B-ADJP'): 0.003424657534246575,\n",
       " ('I-SBAR', 'B-PP'): 5.4374422271763365e-05,\n",
       " ('B-PRT', 'B-ADJP'): 0.0005707762557077625,\n",
       " ('I-ADJP', 'B-ADJP'): 0.003995433789954338,\n",
       " ('I-NP', 'B-CONJP'): 0.22448979591836735,\n",
       " ('I-ADVP', 'B-ADJP'): 0.003424657534246575,\n",
       " ('B-NP', 'B-UCP'): 1.0,\n",
       " ('B-UCP', 'I-UCP'): 0.25,\n",
       " ('I-UCP', 'I-UCP'): 0.75,\n",
       " ('I-UCP', 'B-NP'): 2.1134499957731002e-05,\n",
       " ('O', 'B-PRT'): 0.002136752136752137,\n",
       " ('B-ADJP', 'B-PRT'): 0.002136752136752137,\n",
       " ('O', 'B-LST'): 0.9090909090909091,\n",
       " ('B-LST', 'O'): 0.00034953924372418173,\n",
       " ('B-ADJP', 'B-ADJP'): 0.0017123287671232876,\n",
       " ('B-ADVP', 'B-CONJP'): 0.04081632653061224,\n",
       " ('B-CONJP', 'O'): 9.532888465204957e-05,\n",
       " ('B-NP', 'B-CONJP'): 0.08163265306122448,\n",
       " ('I-SBAR', 'B-VP'): 5.475851494907458e-05,\n",
       " ('I-CONJP', 'O'): 3.1776294884016526e-05,\n",
       " ('I-PP', 'B-ADVP'): 0.0002802690582959641,\n",
       " ('I-VP', 'B-CONJP'): 0.04081632653061224,\n",
       " ('I-INTJ', 'I-INTJ'): 0.2857142857142857,\n",
       " ('B-SBAR', 'B-LST'): 0.09090909090909091,\n",
       " ('B-INTJ', 'B-NP'): 2.1134499957731002e-05,\n",
       " ('B-VP', 'B-INTJ'): 0.07692307692307693,\n",
       " ('B-INTJ', 'B-ADVP'): 0.0002802690582959641,\n",
       " ('B-ADVP', 'B-PRT'): 0.002136752136752137,\n",
       " ('B-INTJ', 'B-PP'): 5.4374422271763365e-05}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "test = pd.read_csv(\"./data/EN/train\", sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\", skip_blank_lines=False)\n",
    "test.replace(np.nan, None, inplace=True)\n",
    "\n",
    "def transitionPara(data):\n",
    "    x, y = split_into_columns(test[\"original\"])\n",
    "    xy_dic = dict(zip(x, y))\n",
    "    \n",
    "    # Get bottom count (Count(yi))\n",
    "    y_count = Counter(y)\n",
    "    \n",
    "    # Get top count (Count(yi-1, yi))\n",
    "    subseq_count = defaultdict(int)\n",
    "    for i in range(len(y)-1):\n",
    "        y1 = y[i]\n",
    "        y2 = y[i+1]\n",
    "        if y1 == None or y2 == None:\n",
    "            continue\n",
    "        subseq_count[y1,y2] += 1\n",
    "    \n",
    "    # Calculation of transition params\n",
    "    result = np.empty(len(y)+2)\n",
    "    emission_dict = {}\n",
    "    \n",
    "    for i in range(0,len(y)):\n",
    "        # account for START and STOP\n",
    "        if i == 0: \n",
    "            result[i] = 1\n",
    "            continue\n",
    "        elif i == len(y):\n",
    "            result[i] = 1\n",
    "            break\n",
    "        \n",
    "        # for all other nodes\n",
    "        y1 = y[i-1]\n",
    "        y2 = y[i]\n",
    "        if y1 == None or y2 == None:\n",
    "            continue\n",
    "        emission_dict[y1,y2] = subseq_count[y1,y2] / y_count[y2]        \n",
    "    \n",
    "    return emission_dict\n",
    "\n",
    "transition_dic = transitionPara(test)\n",
    "transition_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
