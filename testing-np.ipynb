{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning Design Project\n",
    "\n",
    "## About the Project\n",
    "\n",
    "We have 4 datasets in the `/data` folder. For each dataset, there is: \n",
    "- a labelled training set train, \n",
    "- an unlabelled development set `dev.in`\n",
    "- a labelled development set `dev.out` \n",
    "\n",
    "The labelled data has the format of: `token` `\\t` `tag`\n",
    "- one token per line\n",
    "- token and tag separated by tab \n",
    "- single empty lines that separates sentences\n",
    "\n",
    "For the labels, they are slightly different for different datasets.\n",
    "- SG, CN (Entity):\n",
    "    - B-*: Beginning of entity\n",
    "    - I-*: Inside of entity\n",
    "    - O: Outside of any entity\n",
    "- EN, AL (Phrase):\n",
    "    - B-VP: Beginning of Verb Phrase\n",
    "    - I-VP: Inside of Verb Phrase\n",
    "    - *-NP: Noun Phrase\n",
    "    - *PP: Propositional Phrase\n",
    "    - O: Outside of any phrase\n",
    "\n",
    "*Goal*: Build sequence labelling systems from training data (x) and use it to predict tag sequences for new sentences (y).\n",
    "\n",
    "## Team members \n",
    "- Andri Setiawan Susanto\n",
    "- Eldon Lim \n",
    "- Tey Siew Wen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Already completed individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "1. Make a modified training set by replacing those words that appear $<k$ times in the training set with a special word token `#UNK#` before training.\n",
    "2. During testing phase, ifaworddoesnot appear in the modified training set, we also replace that wordwith `#UNK#`.\n",
    "3. Compute Emission Paramters with the function in (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the four datasets EN, AL, CN, and SG, learn these parameters with `train`, and evaluate your\n",
    "system on the development set `dev.in` for each of the dataset. Write your output to `dev.p2.out`\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in `dev.out`\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def emissionPara(arr, k, replaceWord):\n",
    "    x_counter = defaultdict(int)\n",
    "    y_counter = defaultdict(int)\n",
    "    xy_counter = defaultdict(int)\n",
    "    x_labels = defaultdict(list)\n",
    "    emission_params = {}\n",
    "    xy_dict = {}\n",
    "\n",
    "    for x_y in arr:\n",
    "        x, y = x_y[0].split(\" \")\n",
    "        x_counter[x] += 1\n",
    "        y_counter[y] += 1\n",
    "        xy_counter[x,y] += 1\n",
    "        if y not in x_labels[x]:\n",
    "            x_labels[x].append(y)\n",
    "\n",
    "    x_to_remove = [x for x in x_counter if x_counter[x] < k]\n",
    "\n",
    "    for r in x_to_remove:\n",
    "        count = x_counter[r]\n",
    "        for label in x_labels[r]:\n",
    "            x_labels[replaceWord] += x_labels[r]\n",
    "            xy_counter[replaceWord, label] += count\n",
    "        del x_labels[r]\n",
    "        del x_counter[r]\n",
    "\n",
    "    for x_y, x_y_count in xy_counter.items():\n",
    "        y = x_y[1]\n",
    "        emission_params[x_y] = x_y_count / y_counter[y]\n",
    "\n",
    "    # get best labels\n",
    "    for x, labels in x_labels.items():\n",
    "        emission_probs = np.zeros(len(labels))\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            if (x,label) in xy_counter:\n",
    "                emission_probs[i] = xy_counter[x,label]\n",
    "        xy_dict[x] = labels[np.argmax(emission_probs)]\n",
    "    \n",
    "    return emission_params, x_counter.keys(), xy_dict\n",
    "\n",
    "def predict(data, xy_dict, replaceWord):\n",
    "    print(\"Predicting labels\")\n",
    "    start = time.process_time()\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    def replace_string(x):\n",
    "        if x not in xy_dict:\n",
    "            return \"{} {}\".format(replaceWord, xy_dict[replaceWord])\n",
    "        else:\n",
    "            return \"{} {}\".format(x, xy_dict[x])\n",
    "         \n",
    "    return data[\"x\"].apply(lambda s: replace_string(s) if str(s) != \"nan\" else \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#UNK#', 'B-NP') 0.09402811542120283\n",
      "('#UNK#', 'I-NP') 0.1504094081441996\n",
      "('#UNK#', 'I-ADJP') 0.2961672473867596\n",
      "('#UNK#', 'B-ADVP') 0.0726507713884993\n",
      "('#UNK#', 'B-VP') 0.08871365204534254\n",
      "('#UNK#', 'I-VP') 0.12324047642484497\n",
      "('#UNK#', 'B-ADJP') 0.1901770416904626\n",
      "('#UNK#', 'O') 0.0030160857908847183\n",
      "('#UNK#', 'B-PP') 0.0028280850600968075\n",
      "('#UNK#', 'I-ADVP') 0.09917355371900827\n",
      "('#UNK#', 'B-INTJ') 0.4230769230769231\n",
      "('#UNK#', 'I-UCP') 0.5\n",
      "('#UNK#', 'B-SBAR') 0.001579778830963665\n",
      "('#UNK#', 'I-INTJ') 0.5714285714285714\n",
      "('#UNK#', 'B-LST') 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "for k,v in emission_dict.items():\n",
    "    if \"#UNK#\" in k:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis for data folder  SG\n",
      "Predicting labels\n",
      "0                Tour O\n",
      "1    Scotland B-neutral\n",
      "2           followers O\n",
      "Name: x, dtype: object\n",
      "Writing the final result to dev.p2.out...\n"
     ]
    }
   ],
   "source": [
    "from csv import QUOTE_NONE\n",
    "import time\n",
    "\n",
    "k = 3\n",
    "replaceWord = \"#UNK#\"\n",
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in [\"SG\"]:\n",
    "    print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "    test_result = \"./data/{}/dev.out\".format(x)\n",
    "    \n",
    "    train_data = pd.read_csv(train_data, sep='\\r\\n', names=['x_y'],index_col=False, engine=\"python\", encoding=\"UTF-8\").to_numpy()\n",
    "    emission_dict, valid_x, xy_dict = emissionPara(train_data, k, replaceWord)\n",
    "\n",
    "    test_data = pd.read_csv(test_data, sep='\\r\\n', names=['x'],index_col=False,skip_blank_lines=False, engine=\"python\", encoding=\"UTF-8\")\n",
    "    testdf = predict(test_data, xy_dict, replaceWord)\n",
    "    print(testdf.head(3))\n",
    "    \n",
    "    print(\"Writing the final result to dev.p2.out...\")\n",
    "    testdf.to_csv('./output/{}/dev.p2.out'.format(x), header=False, index=False, na_rep=\"\", sep=\"\\n\", quoting=QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that estimates the transition parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_columns(df_column):\n",
    "    new = df_column.str.split(\" \", n=1, expand=True)\n",
    "    return new[0], new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def transitionPara(data):\n",
    "    train_data_blank=pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\", skip_blank_lines=False)\n",
    "    x, y = split_into_columns(train_data_blank[\"original\"])\n",
    "    xy_dic = dict(zip(x, y))\n",
    "    \n",
    "    # Get bottom count (Count(yi))\n",
    "    y_count = Counter(y)\n",
    "    del y_count[np.nan]\n",
    "    # Get top count (Count(yi-1, yi))\n",
    "    subseq_count = defaultdict(int)\n",
    "    for i in range(len(y)-1):    \n",
    "        y1 = y[i]\n",
    "        y2 = y[i+1]\n",
    "        \n",
    "        if i == 0:\n",
    "            subseq_count[(\"START\", y1)] +=1\n",
    "            y_count[\"START\"] +=1\n",
    "        if str(y1) == \"nan\":\n",
    "            subseq_count[(\"START\", y2)] +=1\n",
    "            y_count[\"START\"] +=1\n",
    "        elif i == len(y)-1 or str(y2) == \"nan\":\n",
    "            subseq_count[(y1, \"END\")] +=1\n",
    "            y_count[\"END\"] +=1\n",
    "        else:\n",
    "            subseq_count[y1,y2] += 1\n",
    "    \n",
    "    # Calculation of transition params\n",
    "    transition_dict = {}\n",
    "    \n",
    "    for k,v in subseq_count.items():\n",
    "        y1 = k[0]\n",
    "        y2 = k[1]\n",
    "        transition_dict[y1,y2] = subseq_count[y1,y2] / y_count[y1]\n",
    "     \n",
    "    return transition_dict, subseq_count, y_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({('START', 'B-NP'): 0.6480490669450607,\n",
       "  ('B-NP', 'I-NP'): 0.6847056336539478,\n",
       "  ('I-NP', 'B-VP'): 0.13491234818926195,\n",
       "  ('B-VP', 'B-ADVP'): 0.031214062756694597,\n",
       "  ('B-ADVP', 'B-ADJP'): 0.016549789621318374,\n",
       "  ('B-ADJP', 'I-ADJP'): 0.27984009137635635,\n",
       "  ('I-ADJP', 'I-ADJP'): 0.14634146341463414,\n",
       "  ('I-ADJP', 'B-PP'): 0.2857142857142857,\n",
       "  ('B-PP', 'B-NP'): 0.9280469897209985,\n",
       "  ('I-NP', 'B-PP'): 0.15650931472220694,\n",
       "  ('I-NP', 'O'): 0.2273268487479621,\n",
       "  ('O', 'O'): 0.11352211796246649,\n",
       "  ('O', 'B-ADJP'): 0.008755026809651475,\n",
       "  ('B-NP', 'B-VP'): 0.13030335059718845,\n",
       "  ('B-VP', 'B-PP'): 0.09873500903564975,\n",
       "  ('I-NP', 'I-NP'): 0.4066787565715961,\n",
       "  ('O', 'END'): 0.3182808310991957,\n",
       "  ('B-VP', 'B-SBAR'): 0.025573626855046272,\n",
       "  ('B-SBAR', 'B-NP'): 0.8725645076355977,\n",
       "  ('B-VP', 'B-NP'): 0.3452165817863206,\n",
       "  ('B-VP', 'O'): 0.06741142325173868,\n",
       "  ('O', 'B-NP'): 0.34718498659517427,\n",
       "  ('I-NP', 'B-NP'): 0.0476452162444359,\n",
       "  ('B-ADVP', 'B-PP'): 0.17054698457223003,\n",
       "  ('B-VP', 'I-VP'): 0.3739116149170363,\n",
       "  ('I-VP', 'B-NP'): 0.35534993601732456,\n",
       "  ('O', 'B-VP'): 0.11503016085790885,\n",
       "  ('I-VP', 'I-VP'): 0.3278866030121075,\n",
       "  ('B-NP', 'O'): 0.08096395729838284,\n",
       "  ('B-NP', 'B-PP'): 0.05800655321847585,\n",
       "  ('I-VP', 'B-PP'): 0.1483413721823014,\n",
       "  ('B-PP', 'B-PP'): 0.018491325392940666,\n",
       "  ('B-NP', 'B-NP'): 0.028897579537046823,\n",
       "  ('I-NP', 'B-SBAR'): 0.006374677144584272,\n",
       "  ('B-SBAR', 'B-VP'): 0.038441284886782515,\n",
       "  ('B-NP', 'B-ADVP'): 0.009808688299334109,\n",
       "  ('B-ADVP', 'B-NP'): 0.21037868162692847,\n",
       "  ('B-ADVP', 'I-ADVP'): 0.08695652173913043,\n",
       "  ('I-ADVP', 'B-NP'): 0.18732782369146006,\n",
       "  ('START', 'B-PP'): 0.1087041628604985,\n",
       "  ('I-VP', 'B-SBAR'): 0.013190274633330052,\n",
       "  ('I-VP', 'B-ADVP'): 0.03760212619352298,\n",
       "  ('B-ADVP', 'O'): 0.2653576437587658,\n",
       "  ('I-NP', 'B-ADVP'): 0.015332197614991482,\n",
       "  ('I-ADVP', 'B-ADVP'): 0.030303030303030304,\n",
       "  ('O', 'B-PP'): 0.05014242627345845,\n",
       "  ('START', 'O'): 0.14185045021532036,\n",
       "  ('I-VP', 'O'): 0.05669849394625455,\n",
       "  ('B-VP', 'B-PRT'): 0.011171348776080172,\n",
       "  ('B-PRT', 'B-NP'): 0.5064102564102564,\n",
       "  ('B-ADVP', 'B-VP'): 0.21598877980364656,\n",
       "  ('O', 'B-ADVP'): 0.029197386058981232,\n",
       "  ('B-PP', 'B-VP'): 0.02659487681514113,\n",
       "  ('B-NP', 'B-ADJP'): 0.0032131909946094494,\n",
       "  ('B-ADJP', 'B-PP'): 0.24443175328383782,\n",
       "  ('I-ADVP', 'O'): 0.3278236914600551,\n",
       "  ('B-VP', 'B-VP'): 0.007228519796287169,\n",
       "  ('O', 'B-SBAR'): 0.016127680965147453,\n",
       "  ('I-ADJP', 'B-NP'): 0.08885017421602788,\n",
       "  ('B-NP', 'B-SBAR'): 0.00340344572455343,\n",
       "  ('B-VP', 'B-ADJP'): 0.03920924374349707,\n",
       "  ('B-ADJP', 'B-VP'): 0.11079383209594518,\n",
       "  ('I-NP', 'B-ADJP'): 0.00410324046088183,\n",
       "  ('B-ADJP', 'O'): 0.2569960022844089,\n",
       "  ('B-ADJP', 'B-NP'): 0.051970302684180465,\n",
       "  ('START', 'B-ADVP'): 0.05428683283309409,\n",
       "  ('B-PP', 'O'): 0.008484255180290423,\n",
       "  ('B-ADVP', 'B-SBAR'): 0.016269284712482467,\n",
       "  ('I-VP', 'B-VP'): 0.008268530367162122,\n",
       "  ('I-ADJP', 'O'): 0.3205574912891986,\n",
       "  ('START', 'B-ADJP'): 0.003262429857758058,\n",
       "  ('B-PP', 'I-PP'): 0.011257953989231522,\n",
       "  ('I-PP', 'B-NP'): 0.7847533632286996,\n",
       "  ('B-ADVP', 'B-ADVP'): 0.016269284712482467,\n",
       "  ('START', 'B-SBAR'): 0.02257601461568576,\n",
       "  ('I-PP', 'B-VP'): 0.03139013452914798,\n",
       "  ('I-ADJP', 'B-SBAR'): 0.06097560975609756,\n",
       "  ('B-ADJP', 'B-ADVP'): 0.01599086236436322,\n",
       "  ('B-PP', 'B-ADJP'): 0.0026105400554739763,\n",
       "  ('B-PRT', 'B-PP'): 0.24145299145299146,\n",
       "  ('I-ADVP', 'B-PP'): 0.15426997245179064,\n",
       "  ('I-VP', 'B-ADJP'): 0.029038291170390786,\n",
       "  ('I-ADVP', 'I-ADVP'): 0.14600550964187328,\n",
       "  ('I-VP', 'B-PRT'): 0.023329067821635987,\n",
       "  ('B-ADJP', 'B-SBAR'): 0.03769274700171331,\n",
       "  ('START', 'B-CONJP'): 0.00026099438862064463,\n",
       "  ('B-CONJP', 'I-CONJP'): 0.9387755102040817,\n",
       "  ('I-CONJP', 'B-NP'): 0.4375,\n",
       "  ('START', 'B-VP'): 0.018661098786376094,\n",
       "  ('B-SBAR', 'B-PP'): 0.014218009478672985,\n",
       "  ('B-NP', 'B-PRT'): 0.00035937004544974105,\n",
       "  ('I-ADVP', 'B-SBAR'): 0.07988980716253444,\n",
       "  ('B-PRT', 'B-ADVP'): 0.029914529914529916,\n",
       "  ('I-NP', 'END'): 0.000787675624187137,\n",
       "  ('B-PRT', 'O'): 0.1581196581196581,\n",
       "  ('O', 'B-INTJ'): 0.0005864611260053619,\n",
       "  ('B-INTJ', 'I-INTJ'): 0.19230769230769232,\n",
       "  ('I-INTJ', 'O'): 0.7142857142857143,\n",
       "  ('I-PP', 'B-ADJP'): 0.004484304932735426,\n",
       "  ('B-INTJ', 'O'): 0.6153846153846154,\n",
       "  ('B-SBAR', 'B-SBAR'): 0.00842548709847288,\n",
       "  ('I-PP', 'B-PP'): 0.06278026905829596,\n",
       "  ('I-ADVP', 'B-VP'): 0.05785123966942149,\n",
       "  ('B-PP', 'B-ADVP'): 0.003317561320498178,\n",
       "  ('B-SBAR', 'O'): 0.02843601895734597,\n",
       "  ('B-SBAR', 'B-ADVP'): 0.008952080042127435,\n",
       "  ('B-INTJ', 'B-VP'): 0.07692307692307693,\n",
       "  ('I-PP', 'O'): 0.04035874439461883,\n",
       "  ('I-ADJP', 'B-VP'): 0.06968641114982578,\n",
       "  ('START', 'B-INTJ'): 0.0013049719431032234,\n",
       "  ('B-SBAR', 'I-SBAR'): 0.02527646129541864,\n",
       "  ('I-SBAR', 'B-NP'): 0.9583333333333334,\n",
       "  ('B-PP', 'B-SBAR'): 0.0009789525208027412,\n",
       "  ('I-NP', 'B-PRT'): 0.0001282262644025572,\n",
       "  ('O', 'B-CONJP'): 0.0010472520107238606,\n",
       "  ('I-CONJP', 'I-CONJP'): 0.28125,\n",
       "  ('I-CONJP', 'B-PP'): 0.109375,\n",
       "  ('I-ADJP', 'B-ADVP'): 0.013937282229965157,\n",
       "  ('B-PRT', 'B-VP'): 0.042735042735042736,\n",
       "  ('B-PRT', 'B-SBAR'): 0.019230769230769232,\n",
       "  ('I-PP', 'I-PP'): 0.07174887892376682,\n",
       "  ('B-VP', 'B-CONJP'): 0.0001642845408247084,\n",
       "  ('I-CONJP', 'B-VP'): 0.15625,\n",
       "  ('B-PP', 'END'): 0.00021754500462283134,\n",
       "  ('B-SBAR', 'B-ADJP'): 0.00315955766192733,\n",
       "  ('I-SBAR', 'B-PP'): 0.020833333333333332,\n",
       "  ('B-PRT', 'B-ADJP'): 0.002136752136752137,\n",
       "  ('I-ADJP', 'B-ADJP'): 0.012195121951219513,\n",
       "  ('I-NP', 'B-CONJP'): 0.00020149841548973275,\n",
       "  ('I-ADVP', 'B-ADJP'): 0.01652892561983471,\n",
       "  ('B-NP', 'END'): 0.00023253355882042067,\n",
       "  ('B-NP', 'B-UCP'): 2.1139414438220062e-05,\n",
       "  ('B-UCP', 'I-UCP'): 1.0,\n",
       "  ('I-UCP', 'I-UCP'): 0.75,\n",
       "  ('I-UCP', 'B-NP'): 0.25,\n",
       "  ('O', 'B-PRT'): 4.1890080428954424e-05,\n",
       "  ('B-ADJP', 'B-PRT'): 0.0005711022272986865,\n",
       "  ('START', 'B-LST'): 0.0010439775544825785,\n",
       "  ('B-LST', 'O'): 1.0,\n",
       "  ('B-ADJP', 'B-ADJP'): 0.001142204454597373,\n",
       "  ('B-ADVP', 'B-CONJP'): 0.0005610098176718093,\n",
       "  ('B-CONJP', 'O'): 0.061224489795918366,\n",
       "  ('B-NP', 'B-CONJP'): 8.455765775288025e-05,\n",
       "  ('B-ADVP', 'END'): 0.0008415147265077139,\n",
       "  ('I-SBAR', 'B-VP'): 0.020833333333333332,\n",
       "  ('I-CONJP', 'O'): 0.015625,\n",
       "  ('I-ADJP', 'END'): 0.0017421602787456446,\n",
       "  ('I-PP', 'B-ADVP'): 0.004484304932735426,\n",
       "  ('I-VP', 'B-CONJP'): 0.0001968697706467172,\n",
       "  ('I-VP', 'END'): 9.84348853233586e-05,\n",
       "  ('I-INTJ', 'I-INTJ'): 0.2857142857142857,\n",
       "  ('B-ADJP', 'END'): 0.0005711022272986865,\n",
       "  ('B-SBAR', 'B-LST'): 0.000526592943654555,\n",
       "  ('O', 'B-LST'): 8.378016085790885e-05,\n",
       "  ('B-INTJ', 'B-NP'): 0.038461538461538464,\n",
       "  ('B-VP', 'B-INTJ'): 0.00010952302721647227,\n",
       "  ('B-INTJ', 'B-ADVP'): 0.038461538461538464,\n",
       "  ('B-ADVP', 'B-PRT'): 0.00028050490883590464,\n",
       "  ('B-VP', 'END'): 5.4761513608236134e-05,\n",
       "  ('B-INTJ', 'B-PP'): 0.038461538461538464},\n",
       " defaultdict(int,\n",
       "             {('START', 'B-NP'): 4966,\n",
       "              ('B-NP', 'I-NP'): 32390,\n",
       "              ('I-NP', 'B-VP'): 7365,\n",
       "              ('B-VP', 'B-ADVP'): 570,\n",
       "              ('B-ADVP', 'B-ADJP'): 59,\n",
       "              ('B-ADJP', 'I-ADJP'): 490,\n",
       "              ('I-ADJP', 'I-ADJP'): 84,\n",
       "              ('I-ADJP', 'B-PP'): 164,\n",
       "              ('B-PP', 'B-NP'): 17064,\n",
       "              ('I-NP', 'B-PP'): 8544,\n",
       "              ('I-NP', 'O'): 12410,\n",
       "              ('O', 'O'): 2710,\n",
       "              ('O', 'B-ADJP'): 209,\n",
       "              ('B-NP', 'B-VP'): 6164,\n",
       "              ('B-VP', 'B-PP'): 1803,\n",
       "              ('I-NP', 'I-NP'): 22201,\n",
       "              ('O', 'END'): 7598,\n",
       "              ('B-VP', 'B-SBAR'): 467,\n",
       "              ('B-SBAR', 'B-NP'): 1657,\n",
       "              ('B-VP', 'B-NP'): 6304,\n",
       "              ('B-VP', 'O'): 1231,\n",
       "              ('O', 'B-NP'): 8288,\n",
       "              ('I-NP', 'B-NP'): 2601,\n",
       "              ('B-ADVP', 'B-PP'): 608,\n",
       "              ('B-VP', 'I-VP'): 6828,\n",
       "              ('I-VP', 'B-NP'): 3610,\n",
       "              ('O', 'B-VP'): 2746,\n",
       "              ('I-VP', 'I-VP'): 3331,\n",
       "              ('B-NP', 'O'): 3830,\n",
       "              ('B-NP', 'B-PP'): 2744,\n",
       "              ('I-VP', 'B-PP'): 1507,\n",
       "              ('B-PP', 'B-PP'): 340,\n",
       "              ('B-NP', 'B-NP'): 1367,\n",
       "              ('I-NP', 'B-SBAR'): 348,\n",
       "              ('B-SBAR', 'B-VP'): 73,\n",
       "              ('B-NP', 'B-ADVP'): 464,\n",
       "              ('B-ADVP', 'B-NP'): 750,\n",
       "              ('B-ADVP', 'I-ADVP'): 310,\n",
       "              ('I-ADVP', 'B-NP'): 68,\n",
       "              ('START', 'B-PP'): 833,\n",
       "              ('I-VP', 'B-SBAR'): 134,\n",
       "              ('I-VP', 'B-ADVP'): 382,\n",
       "              ('B-ADVP', 'O'): 946,\n",
       "              ('I-NP', 'B-ADVP'): 837,\n",
       "              ('I-ADVP', 'B-ADVP'): 11,\n",
       "              ('O', 'B-PP'): 1197,\n",
       "              ('START', 'O'): 1087,\n",
       "              ('I-VP', 'O'): 576,\n",
       "              ('B-VP', 'B-PRT'): 204,\n",
       "              ('B-PRT', 'B-NP'): 237,\n",
       "              ('B-ADVP', 'B-VP'): 770,\n",
       "              ('O', 'B-ADVP'): 697,\n",
       "              ('B-PP', 'B-VP'): 489,\n",
       "              ('B-NP', 'B-ADJP'): 152,\n",
       "              ('B-ADJP', 'B-PP'): 428,\n",
       "              ('I-ADVP', 'O'): 119,\n",
       "              ('B-VP', 'B-VP'): 132,\n",
       "              ('O', 'B-SBAR'): 385,\n",
       "              ('I-ADJP', 'B-NP'): 51,\n",
       "              ('B-NP', 'B-SBAR'): 161,\n",
       "              ('B-VP', 'B-ADJP'): 716,\n",
       "              ('B-ADJP', 'B-VP'): 194,\n",
       "              ('I-NP', 'B-ADJP'): 224,\n",
       "              ('B-ADJP', 'O'): 450,\n",
       "              ('B-ADJP', 'B-NP'): 91,\n",
       "              ('START', 'B-ADVP'): 416,\n",
       "              ('B-PP', 'O'): 156,\n",
       "              ('B-ADVP', 'B-SBAR'): 58,\n",
       "              ('I-VP', 'B-VP'): 84,\n",
       "              ('I-ADJP', 'O'): 184,\n",
       "              ('START', 'B-ADJP'): 25,\n",
       "              ('B-PP', 'I-PP'): 207,\n",
       "              ('I-PP', 'B-NP'): 175,\n",
       "              ('B-ADVP', 'B-ADVP'): 58,\n",
       "              ('START', 'B-SBAR'): 173,\n",
       "              ('I-PP', 'B-VP'): 7,\n",
       "              ('I-ADJP', 'B-SBAR'): 35,\n",
       "              ('B-ADJP', 'B-ADVP'): 28,\n",
       "              ('B-PP', 'B-ADJP'): 48,\n",
       "              ('B-PRT', 'B-PP'): 113,\n",
       "              ('I-ADVP', 'B-PP'): 56,\n",
       "              ('I-VP', 'B-ADJP'): 295,\n",
       "              ('I-ADVP', 'I-ADVP'): 53,\n",
       "              ('I-VP', 'B-PRT'): 237,\n",
       "              ('B-ADJP', 'B-SBAR'): 66,\n",
       "              ('START', 'B-CONJP'): 2,\n",
       "              ('B-CONJP', 'I-CONJP'): 46,\n",
       "              ('I-CONJP', 'B-NP'): 28,\n",
       "              ('START', 'B-VP'): 143,\n",
       "              ('B-SBAR', 'B-PP'): 27,\n",
       "              ('B-NP', 'B-PRT'): 17,\n",
       "              ('I-ADVP', 'B-SBAR'): 29,\n",
       "              ('B-PRT', 'B-ADVP'): 14,\n",
       "              ('I-NP', 'END'): 43,\n",
       "              ('B-PRT', 'O'): 74,\n",
       "              ('O', 'B-INTJ'): 14,\n",
       "              ('B-INTJ', 'I-INTJ'): 5,\n",
       "              ('I-INTJ', 'O'): 5,\n",
       "              ('I-PP', 'B-ADJP'): 1,\n",
       "              ('B-INTJ', 'O'): 16,\n",
       "              ('B-SBAR', 'B-SBAR'): 16,\n",
       "              ('I-PP', 'B-PP'): 14,\n",
       "              ('I-ADVP', 'B-VP'): 21,\n",
       "              ('B-PP', 'B-ADVP'): 61,\n",
       "              ('B-SBAR', 'O'): 54,\n",
       "              ('B-SBAR', 'B-ADVP'): 17,\n",
       "              ('B-INTJ', 'B-VP'): 2,\n",
       "              ('I-PP', 'O'): 9,\n",
       "              ('I-ADJP', 'B-VP'): 40,\n",
       "              ('START', 'B-INTJ'): 10,\n",
       "              ('B-SBAR', 'I-SBAR'): 48,\n",
       "              ('I-SBAR', 'B-NP'): 46,\n",
       "              ('B-PP', 'B-SBAR'): 18,\n",
       "              ('I-NP', 'B-PRT'): 7,\n",
       "              ('O', 'B-CONJP'): 25,\n",
       "              ('I-CONJP', 'I-CONJP'): 18,\n",
       "              ('I-CONJP', 'B-PP'): 7,\n",
       "              ('I-ADJP', 'B-ADVP'): 8,\n",
       "              ('B-PRT', 'B-VP'): 20,\n",
       "              ('B-PRT', 'B-SBAR'): 9,\n",
       "              ('I-PP', 'I-PP'): 16,\n",
       "              ('B-VP', 'B-CONJP'): 3,\n",
       "              ('I-CONJP', 'B-VP'): 10,\n",
       "              ('B-PP', 'END'): 4,\n",
       "              ('B-SBAR', 'B-ADJP'): 6,\n",
       "              ('I-SBAR', 'B-PP'): 1,\n",
       "              ('B-PRT', 'B-ADJP'): 1,\n",
       "              ('I-ADJP', 'B-ADJP'): 7,\n",
       "              ('I-NP', 'B-CONJP'): 11,\n",
       "              ('I-ADVP', 'B-ADJP'): 6,\n",
       "              ('B-NP', 'END'): 11,\n",
       "              ('B-NP', 'B-UCP'): 1,\n",
       "              ('B-UCP', 'I-UCP'): 1,\n",
       "              ('I-UCP', 'I-UCP'): 3,\n",
       "              ('I-UCP', 'B-NP'): 1,\n",
       "              ('O', 'B-PRT'): 1,\n",
       "              ('B-ADJP', 'B-PRT'): 1,\n",
       "              ('START', 'B-LST'): 8,\n",
       "              ('B-LST', 'O'): 11,\n",
       "              ('B-ADJP', 'B-ADJP'): 2,\n",
       "              ('B-ADVP', 'B-CONJP'): 2,\n",
       "              ('B-CONJP', 'O'): 3,\n",
       "              ('B-NP', 'B-CONJP'): 4,\n",
       "              ('B-ADVP', 'END'): 3,\n",
       "              ('I-SBAR', 'B-VP'): 1,\n",
       "              ('I-CONJP', 'O'): 1,\n",
       "              ('I-ADJP', 'END'): 1,\n",
       "              ('I-PP', 'B-ADVP'): 1,\n",
       "              ('I-VP', 'B-CONJP'): 2,\n",
       "              ('I-VP', 'END'): 1,\n",
       "              ('I-INTJ', 'I-INTJ'): 2,\n",
       "              ('B-ADJP', 'END'): 1,\n",
       "              ('B-SBAR', 'B-LST'): 1,\n",
       "              ('O', 'B-LST'): 2,\n",
       "              ('B-INTJ', 'B-NP'): 1,\n",
       "              ('B-VP', 'B-INTJ'): 2,\n",
       "              ('B-INTJ', 'B-ADVP'): 1,\n",
       "              ('B-ADVP', 'B-PRT'): 1,\n",
       "              ('B-VP', 'END'): 1,\n",
       "              ('B-INTJ', 'B-PP'): 1}),\n",
       " Counter({'B-NP': 47305,\n",
       "          'I-NP': 54591,\n",
       "          'B-VP': 18261,\n",
       "          'B-ADVP': 3565,\n",
       "          'B-ADJP': 1751,\n",
       "          'I-ADJP': 574,\n",
       "          'B-PP': 18387,\n",
       "          'O': 23872,\n",
       "          'B-SBAR': 1899,\n",
       "          'I-VP': 10159,\n",
       "          'I-ADVP': 363,\n",
       "          'B-PRT': 468,\n",
       "          'I-PP': 223,\n",
       "          'B-CONJP': 49,\n",
       "          'I-CONJP': 64,\n",
       "          'B-INTJ': 26,\n",
       "          'I-INTJ': 7,\n",
       "          'I-SBAR': 48,\n",
       "          'B-UCP': 1,\n",
       "          'I-UCP': 4,\n",
       "          'B-LST': 11,\n",
       "          'START': 7663,\n",
       "          'END': 7663}))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitionPara(\"./data/EN/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(unique_word_list):\n",
    "    #This is for the starting for viterbi\n",
    "    global nodes\n",
    "    \n",
    "    num_nodes_per_col = len(nodes)\n",
    "    store=np.zeros(num_nodes_per_col)   #store = the storage for scores for all the nodes. \n",
    "    scorelist=np.zeros((num_nodes_per_col, len(unique_word_list) + 1))\n",
    "    \n",
    "    for i in range(num_nodes_per_col):\n",
    "        emission_score = emission(nodes[i],unique_word_list[0])\n",
    "        transition_score = transition(\"START\",nodes[i])\n",
    "        if transition_score == 0:\n",
    "            store[i] = 0\n",
    "        else:\n",
    "            store[i] = np.log(emission_score)+np.log(transition_score)  \n",
    "    scorelist[:,0] = store\n",
    "    store = np.zeros(num_nodes_per_col)\n",
    "    score_per_node=np.zeros(num_nodes_per_col)\n",
    "    \n",
    "    #This is for the middle portion for viterbi\n",
    "    #score per node = prevnode*emission*transition\n",
    "\n",
    "    if len(unique_word_list)>1:\n",
    "        for j in range(len(unique_word_list)-1): #for the whole length in sentence\n",
    "            for k in range(num_nodes_per_col): #for each node\n",
    "                for l in range(num_nodes_per_col): #for 1 node, transition from prev node to current node\n",
    "                    prev_node = scorelist[l][j]\n",
    "                    curr_emission = emission(nodes[k],unique_word_list[j+1])\n",
    "                    curr_transition = transition(nodes[l],nodes[k])\n",
    "                    score_per_node[l] = prev_node+np.log(curr_emission)+np.log(curr_transition) \n",
    "                \n",
    "                store[k] = np.max(score_per_node) # max path\n",
    "                score_per_node=np.zeros(num_nodes_per_col)\n",
    "            \n",
    "            scorelist[:,j+1] = store\n",
    "            store = np.zeros(num_nodes_per_col)\n",
    "                      \n",
    "        score_at_stop=np.zeros(num_nodes_per_col)\n",
    "        \n",
    "        #This is for the STOP for viterbi\n",
    "        for m in range(num_nodes_per_col):\n",
    "            score_at_stop[m] = np.log(transition(nodes[m],\"END\")) + scorelist[m][len(unique_word_list)-1]\n",
    "        scorelist[:,-1] = np.full(num_nodes_per_col,np.max(score_at_stop))\n",
    "        \n",
    "    return scorelist\n",
    "  \n",
    "def viterbi_backtrack(scorelist):\n",
    "    \"\"\"\n",
    "    back tracking for viterbi\n",
    "    node value*transition = array, then find max, then find position. use position for next step.\n",
    "    np.argmax returns index of max in the element.\n",
    "    The final score on the score list is for end\n",
    "    \"\"\" \n",
    "    global nodes\n",
    "    \n",
    "    scorelist = np.flip(scorelist,axis=1) #reverse the score list so easier to calculate.\n",
    "    \n",
    "#     print(\"After flipping\")\n",
    "    max_node_index = 0 \n",
    "    num_obs = scorelist.shape[1]\n",
    "    num_nodes = scorelist.shape[0]\n",
    "    node_holder = np.zeros(num_nodes)\n",
    "    path = []\n",
    "#     print(\"num obs\", num_obs)\n",
    "#     print(\"num nodes\", num_nodes)\n",
    "\n",
    "    if (num_obs == 1):\n",
    "        for k in range (num_nodes):\n",
    "            calculate_max_node = scorelist[0][k] + np.log(transition(nodes[k],\"END\"))\n",
    "            node_holder[i] = calculate_max_node\n",
    "        path.append(nodes[np.argmax(node_holder)])\n",
    "        return(path[::-1])\n",
    "\n",
    "    for i in range (1,num_obs): # for length of sentence\n",
    "        for j in range(num_nodes): #for each node\n",
    "            if (i==1):\n",
    "                calculate_max_node = scorelist[j][i] + np.log(transition(nodes[j],\"END\"))\n",
    "                node_holder[j] = calculate_max_node\n",
    "            else:\n",
    "                calculate_max_node = scorelist[j][i] + np.log(transition(nodes[j],nodes[max_node_index]))\n",
    "                node_holder[j] = calculate_max_node\n",
    "        \n",
    "        max_node_index=np.argmax(node_holder)\n",
    "        path.append(nodes[np.argmax(node_holder)])\n",
    "        node_holder=np.zeros(num_nodes)\n",
    "\n",
    "    return(path[::-1])\n",
    "\n",
    "def emission(node,word):\n",
    "    global emission_dict\n",
    "    global nodes\n",
    "    pair = word,node\n",
    "    detector = 0 # this is used to find if word exist in the dictionary\n",
    "    if pair not in emission_dict.keys(): #if the combination cannot be found in the dictionary\n",
    "                                         #Either the word exists, or word is new. \n",
    "        for o in nodes:\n",
    "            missing_pair = word,o\n",
    "            if missing_pair in emission_dict.keys(): #\n",
    "                detector = 1 # to detect if word exist in dictionary.\n",
    "                break\n",
    "        if detector == 1:\n",
    "            score=0   #this means that this node is not the correct node.\n",
    "        else:\n",
    "            replaced_text = \"#UNK#\",node\n",
    "            if replaced_text in emission_dict.keys():\n",
    "                score = emission_dict[replaced_text] #if label have #unk#\n",
    "                \n",
    "            else:\n",
    "                score = 0   #if label does not have #unk#, then set to 0.\n",
    "    else:\n",
    "        score = emission_dict[pair]\n",
    "    return score\n",
    "\n",
    "def transition(x1,x2):\n",
    "    global transition_dic\n",
    "    #will use this to search the transition from x1 to x2\n",
    "    pair = x1,x2\n",
    "    if pair not in transition_dic.keys():\n",
    "        score = 0\n",
    "    else:\n",
    "        score = transition_dic[x1,x2]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_blank_row(data):\n",
    "    start = time.process_time()   \n",
    "    \n",
    "    df= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False,engine=\"python\",skip_blank_lines=False)\n",
    "    # dropping null value columns to avoid errors \n",
    "    \n",
    "    # new data frame with split value columns \n",
    "    df[\"x\"], df[\"y\"] = split_into_columns(df[\"original\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceList(data):\n",
    "    lines=[]\n",
    "    line=[]\n",
    "    x= data\n",
    "    for label in x['x']:\n",
    "        if pd.isnull(label)==False:\n",
    "            line.append(label)\n",
    "        else:\n",
    "            lines.append(line)\n",
    "            line = []\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalresult(sequence_log,predata_blank):\n",
    "    dataframe = []\n",
    "    count=0\n",
    "    for i in range(len(sequence_log)):\n",
    "        for text in sequence_log[i]:\n",
    "            dataframe.append(text)\n",
    "            count+=1\n",
    "        dataframe.append(\"\")\n",
    "    dftest=pd.DataFrame(dataframe)\n",
    "    final = pd.DataFrame()\n",
    "    final['result'] = predata_blank['x'] + \" \" +dftest[0]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis for data folder  EN\n",
      "Performing Viterbi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:80: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Viterbi and Backtrack 201.21180987358093\n",
      "Writing the final result to dev.p3.out...\n",
      "Finished Writing.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in [\"EN\"]:\n",
    "    print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "    \n",
    "    transition_dic, subseq_count, y_count = transitionPara(train_data)\n",
    "    predata_blank=preprocess_training_blank_row(train_data)\n",
    "    nodes = list(y_count.keys())\n",
    "    testdf_unprocess = pd.read_csv(test_data, sep='/n', delimiter=None, names=['x'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "    lines= sentenceList(testdf_unprocess)\n",
    "    \n",
    "    log_array =[]\n",
    "    sequence_log=[]\n",
    "    \n",
    "    print(\"Performing Viterbi\")\n",
    "    start = time.time()\n",
    "    for i in range(len(lines)):\n",
    "        viterbioutput=viterbi(lines[i])\n",
    "        log_array.append(viterbioutput)\n",
    "        sequence_log.append(viterbi_backtrack(viterbioutput))\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time taken for Viterbi and Backtrack\", end - start)\n",
    "    \n",
    "    result = finalresult(sequence_log,testdf_unprocess)\n",
    "    \n",
    "    print(\"Writing the final result to dev.p3.out...\")\n",
    "    f = open('./output/{}/dev.p3.out'.format(x) ,'w')\n",
    "    for word in result['result']:\n",
    "        if pd.isnull(word) == False:\n",
    "            f.write(word + '\\n')\n",
    "        else:\n",
    "            f.write(\"\" +\"\\n\")\n",
    "    f.close()\n",
    "    print(\"Finished Writing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
