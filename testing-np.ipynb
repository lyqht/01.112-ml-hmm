{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.112 Machine Learning Design Project\n",
    "\n",
    "## About the Project\n",
    "\n",
    "We have 4 datasets in the `/data` folder. For each dataset, there is: \n",
    "- a labelled training set train, \n",
    "- an unlabelled development set `dev.in`\n",
    "- a labelled development set `dev.out` \n",
    "\n",
    "The labelled data has the format of: `token` `\\t` `tag`\n",
    "- one token per line\n",
    "- token and tag separated by tab \n",
    "- single empty lines that separates sentences\n",
    "\n",
    "For the labels, they are slightly different for different datasets.\n",
    "- SG, CN (Entity):\n",
    "    - B-*: Beginning of entity\n",
    "    - I-*: Inside of entity\n",
    "    - O: Outside of any entity\n",
    "- EN, AL (Phrase):\n",
    "    - B-VP: Beginning of Verb Phrase\n",
    "    - I-VP: Inside of Verb Phrase\n",
    "    - *-NP: Noun Phrase\n",
    "    - *PP: Propositional Phrase\n",
    "    - O: Outside of any phrase\n",
    "\n",
    "*Goal*: Build sequence labelling systems from training data (x) and use it to predict tag sequences for new sentences (y).\n",
    "\n",
    "## Team members \n",
    "- Andri Setiawan Susanto\n",
    "- Eldon Lim \n",
    "- Tey Siew Wen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Already completed individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "1. Make a modified training set by replacing those words that appear $<k$ times in the training set with a special word token `#UNK#` before training.\n",
    "2. During testing phase, ifaworddoesnot appear in the modified training set, we also replace that wordwith `#UNK#`.\n",
    "3. Compute Emission Paramters with the function in (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the four datasets EN, AL, CN, and SG, learn these parameters with `train`, and evaluate your\n",
    "system on the development set `dev.in` for each of the dataset. Write your output to `dev.p2.out`\n",
    "for the four datasets respectively. Compare your outputs and the gold-standard outputs in `dev.out`\n",
    "and report the precision, recall and F scores of such a baseline system for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "\n",
    "def emissionPara(df):\n",
    "    x_y_lists = df['x_y'].str.split(\" \")\n",
    "    x_y_tuples = x_y_lists.apply(lambda x: tuple(x)).to_numpy()\n",
    "    x_y_counter = Counter(x_y_tuples)\n",
    "    \n",
    "    y_counter = Counter(x_y_lists.apply(lambda s: s[1]))\n",
    "    \n",
    "    emission_params = {}\n",
    "    \n",
    "    for x_y, x_y_count in x_y_counter.items():\n",
    "        y = x_y[1]\n",
    "        emission_params[x_y] = x_y_count / y_counter[y]\n",
    "    return emission_params\n",
    "\n",
    "k = 3\n",
    "replaceWord = \"#UNK#\"\n",
    "test_data = \"./data/EN/train\"\n",
    "test_data = pd.read_csv(test_data, sep='/n', delimiter=None, names=['x_y'],index_col=False, engine=\"python\")\n",
    "\n",
    "def preprocess(df, k, replaceWord):\n",
    "    \"\"\"\n",
    "    Function to modify train/test data based on the occurence of words. \n",
    "    If a word appears <= k times in the data, replace it with the replaceWord.\n",
    "    Returns a new df.\n",
    "    \"\"\"\n",
    "    x_y_lists = df['x_y'].str.split(\" \")\n",
    "    x = x_y_lists.apply(lambda s: s[0])\n",
    "    \n",
    "    invalid_x = x.value_counts()[x.value_counts() < 3].index.to_list()\n",
    "    valid_x = x.value_counts()[x.value_counts() >= 3].index.to_list()\n",
    "\n",
    "    print(\"There are \", len(x), \"observations\")\n",
    "    print(\"Out of those observations, \", len(invalid_x), \"is to be replaced.\")\n",
    "    \n",
    "    def replace_with_string(s):\n",
    "        x, y = s\n",
    "        if x in invalid_x:\n",
    "            return \"{} {}\".format(replaceWord, y)\n",
    "        else:\n",
    "            return \"{} {}\".format(x, y)\n",
    "        \n",
    "    new_df = pd.DataFrame(x_y_lists.apply(replace_with_string), columns=[\"x_y\"])\n",
    "    return new_df, valid_x, invalid_x\n",
    "\n",
    "def preprocess_test(data,k):\n",
    "    global replaceWord\n",
    "    \n",
    "    start = time.process_time()   \n",
    "\n",
    "    testdf1= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "    testdf= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "\n",
    "    x_dic = {}\n",
    "\n",
    "    uniqueX, uniqueCountX= np.unique(testdf1['original'].astype(str),return_counts=True)\n",
    "    for i in range(len(uniqueX)):\n",
    "        x_dic[uniqueX[i]] = uniqueCountX[i]\n",
    "\n",
    "    testdf['modified']=''\n",
    "#     print(testdf)\n",
    "    for i, text in enumerate(testdf['original']):\n",
    "    #         df['x'][i] = replaceWord\n",
    "        try:\n",
    "            if text not in xy_pred_dic:\n",
    "            \n",
    "                testdf['modified'][i]=testdf['original'][i].replace(text,replaceWord)\n",
    "            else:\n",
    "                testdf['modified'][i]=testdf['original'][i]\n",
    "        except:\n",
    "            continue\n",
    "    testdf['predict_label']=''\n",
    "    for index, word in enumerate(testdf['modified']):\n",
    "#     print(word)\n",
    "        try:\n",
    "            testdf['predict_label'][index]= xy_pred_dic[word]\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Time taken for test data: \",time.process_time() - start)\n",
    "    return testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis for data folder  EN\n",
      "There are  181628 observations\n",
      "Out of those observations,  12026 is to be replaced.\n",
      "Time taken for test data:  0.25\n",
      "Writing the final result to dev.p2..out...\n"
     ]
    }
   ],
   "source": [
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in [\"EN\"]:\n",
    "    print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "    test_result = \"./data/{}/dev.out\".format(x)\n",
    "    \n",
    "    train_data = pd.read_csv(train_data, sep='/n', delimiter=None, names=['x_y'],index_col=False, engine=\"python\")\n",
    "    predata, valid_x, invalid_x = preprocess(train_data, k, replaceWord)\n",
    "\n",
    "    emission_dict = emissionPara(predata)\n",
    "    \n",
    "    \n",
    "    testdf = preprocess_test(test_data,k)\n",
    "    final = pd.DataFrame()\n",
    "    final['result'] = testdf['modified'] + ' ' + testdf['predict_label']\n",
    "\n",
    "    print(\"Writing the final result to dev.p2..out...\")\n",
    "    f = open('./output/{}/dev.p2.out'.format(x) ,'w')\n",
    "    for word in final['result']:\n",
    "        f.write(word + '\\n')\n",
    "    f.close()\n",
    "    \n",
    "#     print(\"Writing the final result to dev.p2..out...\")\n",
    "#     testdf.to_csv('./output/{}/dev.p2.out'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that estimates the transition parameters from the training set using MLE (maximum likelihood estimation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_columns(df_column):\n",
    "    new = df_column.str.split(\" \", n=1, expand=True)\n",
    "    return new[0], new[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def transitionPara(data):\n",
    "    train_data_blank=pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\", skip_blank_lines=False)\n",
    "    x, y = split_into_columns(train_data_blank[\"original\"])\n",
    "    xy_dic = dict(zip(x, y))\n",
    "    \n",
    "    # Get bottom count (Count(yi))\n",
    "    y_count = Counter(y)\n",
    "    \n",
    "    # Get top count (Count(yi-1, yi))\n",
    "    subseq_count = defaultdict(int)\n",
    "    for i in range(len(y)-1):    \n",
    "        y1 = y[i]\n",
    "        y2 = y[i+1]\n",
    "        \n",
    "        if i == 0:\n",
    "            subseq_count[(\"START\", y1)] +=1\n",
    "            y_count[\"START\"] +=1\n",
    "        if pd.isna(y1):\n",
    "            subseq_count[(\"START\", y2)] +=1\n",
    "            y_count[\"START\"] +=1\n",
    "        elif i == len(y)-1 or pd.isna(y2):\n",
    "            subseq_count[(y1, \"END\")] +=1\n",
    "            y_count[\"END\"] +=1\n",
    "        else:\n",
    "            subseq_count[y1,y2] += 1\n",
    "    \n",
    "    # Calculation of transition params\n",
    "    result = np.empty(len(y)+2)\n",
    "    transition_dict = {}\n",
    "    \n",
    "    for k,v in subseq_count.items():\n",
    "        y1 = k[0]\n",
    "        y2 = k[1]\n",
    "        transition_dict[y1,y2] = subseq_count[y1,y2] / y_count[y2]\n",
    "     \n",
    "    return transition_dict, subseq_count, y_count\n",
    "\n",
    "# transition_dic, subseq_count, y_count = transitionPara(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(unique_word_list):\n",
    "    #This is for the starting for viterbi\n",
    "    global nodes\n",
    "    num_nodes_per_col = len(nodes)\n",
    "    store=np.zeros(num_nodes_per_col)   #store = the storage for scores for all the nodes. \n",
    "    scorelist=np.zeros((len(unique_word_list) + 1, num_nodes_per_col))\n",
    "    \n",
    "    for i in range(num_nodes_per_col):\n",
    "        emission_score = emission(nodes[i],unique_word_list[0])\n",
    "        transition_score = transition(\"START\",nodes[i])\n",
    "        store[i] = np.log(emission_score)+np.log(transition_score)  \n",
    "        \n",
    "    scorelist[0] = store\n",
    "    store = np.zeros(num_nodes_per_col)\n",
    "    score_per_node=np.zeros(num_nodes_per_col)\n",
    "    \n",
    "    #This is for the middle portion for viterbi\n",
    "    #score per node = prevnode*emission*transition\n",
    "\n",
    "    if len(unique_word_list)>1:\n",
    "        for j in range(len(unique_word_list)-1): #for the whole length in sentence\n",
    "            for k in range(num_nodes_per_col): #for each node\n",
    "                for l in range(num_nodes_per_col): #for 1 node, transition from prev node to current node\n",
    "                    prev_node = scorelist[j][l]\n",
    "                    curr_emission = emission(nodes[k],unique_word_list[j+1])\n",
    "                    curr_transition = transition(nodes[l],nodes[k])\n",
    "                    score_per_node[l] = prev_node+np.log(curr_emission)+np.log(curr_transition) \n",
    "                \n",
    "                store[k] = np.max(score_per_node) # max path\n",
    "                score_per_node=np.zeros(num_nodes_per_col)\n",
    "            \n",
    "            scorelist[j+1,:] = store\n",
    "            store = np.zeros(num_nodes_per_col)\n",
    "                      \n",
    "        score_at_stop=np.zeros(num_nodes_per_col)\n",
    "        \n",
    "        #This is for the STOP for viterbi\n",
    "        for m in range(num_nodes_per_col):\n",
    "            score_at_stop[m] = np.log(transition(nodes[m],\"END\")) + scorelist[len(unique_word_list)-1][m]\n",
    "        scorelist[-1] = np.full(num_nodes_per_col,np.max(score_at_stop))\n",
    "        \n",
    "    return scorelist\n",
    "\n",
    "def emission(node,word):\n",
    "    global emission_dict\n",
    "    global nodes\n",
    "    pair = word,node\n",
    "    detector = 0 # this is used to find if word exist in the dictionary\n",
    "    if pair not in emission_dict.keys(): #if the combination cannot be found in the dictionary\n",
    "                                         #Either the word exists, or word is new. \n",
    "        for o in nodes:\n",
    "            missing_pair = word,o\n",
    "            if missing_pair in emission_dict.keys(): #\n",
    "                detector = 1 # to detect if word exist in dictionary.\n",
    "                break\n",
    "        if detector == 1:\n",
    "            score=0   #this means that this node is not the correct node.\n",
    "        else:\n",
    "            replaced_text = \"#UNK#\",node\n",
    "            if replaced_text in emission_dict.keys():\n",
    "                score = emission_dict[replaced_text] #if label have #unk#\n",
    "                \n",
    "            else:\n",
    "                score = 0   #if label does not have #unk#, then set to 0.\n",
    "    else:\n",
    "        score = emission_dict[pair]\n",
    "    return score\n",
    "\n",
    "def transition(x1,x2):\n",
    "    global transition_dic\n",
    "    #will use this to search the transition from x1 to x2\n",
    "    pair = x1,x2\n",
    "    if pair not in transition_dic.keys():\n",
    "        score = 0\n",
    "    else:\n",
    "        score = transition_dic[x1,x2]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #('#UNK#', \"B-NP\") in emission_dict\n",
    "# print(len(valid_x))\n",
    "# #print(len(emission_dict))\n",
    "# word_list=[]\n",
    "# word_list2=[]\n",
    "# for i in range((len(lines))): #iterated through the list lines for all possible words\n",
    "#     for word in lines[i]:\n",
    "#         for o in nodes: # for all nodes, keep unique word in the dictionary\n",
    "#             temp=word,o\n",
    "#             if temp in emission_dict.keys():\n",
    "#                 if word not in word_list:\n",
    "#                     word_list.append(word)\n",
    "                    \n",
    "# for i in range((len(lines))): #iterated through the list lines for all possible words\n",
    "#     for word in lines[i]:\n",
    "#         for o in nodes: # for all nodes, keep unique word in the dictionary\n",
    "#             if word in valid_x:\n",
    "#                 if word not in word_list2:\n",
    "#                         word_list2.append(word)\n",
    "                    \n",
    "# print(\"Node word count :\" + str(len(word_list)) )\n",
    "# print(\"Valid_X word count:\" + str(len(word_list2)) )\n",
    "\n",
    "# for k in word_list2:\n",
    "#     word_list.remove(k)\n",
    "    \n",
    "# print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backtrack(scorelist):\n",
    "    \"\"\"\n",
    "    back tracking for viterbi\n",
    "    node value*transition = array, then find max, then find position. use position for next step.\n",
    "    np.argmax returns index of max in the element.\n",
    "    The final score on the score list is for end\n",
    "    \"\"\" \n",
    "    global nodes\n",
    "    \n",
    "    print(scorelist.shape)\n",
    "    scorelist = np.flip(scorelist,axis=1) #reverse the score list so easier to calculate.\n",
    "    max_node_index = 0 \n",
    "    num_obs = scorelist.shape[0] #columns\n",
    "    num_nodes = scorelist.shape[1] #rows\n",
    "    node_holder = np.zeros(num_nodes)\n",
    "    path = []\n",
    "\n",
    "    if (num_obs == 1):\n",
    "        for k in range (num_nodes):\n",
    "            calculate_max_node = scorelist[0][k] + np.log(transition(nodes[k],\"END\"))\n",
    "            node_holder[i] = calculate_max_node\n",
    "        path.append(nodes[np.argmax(node_holder)])\n",
    "        return(path[::-1])\n",
    "\n",
    "    for i in range (1,num_obs): # for length of sentence\n",
    "\n",
    "        for j in range(num_nodes): #for each node\n",
    "            #each node*own path, find max\n",
    "            if (i==1):\n",
    "                calculate_max_node = scorelist[i][j] + np.log(transition(nodes[j],\"END\"))\n",
    "                node_holder[j] = calculate_max_node\n",
    "            else:\n",
    "                calculate_max_node = scorelist[i][j] + np.log(transition(nodes[j],nodes[max_node_index]))\n",
    "                node_holder[j] = calculate_max_node\n",
    "        \n",
    "        max_node_index=np.argmax(node_holder)\n",
    "        path.append(nodes[np.argmax(node_holder)])\n",
    "        node_holder=np.zeros(num_nodes)\n",
    "\n",
    "    return(path[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_blank_row(data):\n",
    "    start = time.process_time()   \n",
    "    \n",
    "    df= pd.read_csv(data, sep='/n', delimiter=None, names=['original'],index_col=False,engine=\"python\",skip_blank_lines=False)\n",
    "    # dropping null value columns to avoid errors \n",
    "    \n",
    "    # new data frame with split value columns \n",
    "    df[\"x\"], df[\"y\"] = split_into_columns(df[\"original\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceList(data):\n",
    "    lines=[]\n",
    "    line=[]\n",
    "    x= data\n",
    "    for label in x['x']:\n",
    "        if pd.isnull(label)==False:\n",
    "            line.append(label)\n",
    "        else:\n",
    "    #         line += ' stop'\n",
    "            lines.append(line)\n",
    "            line = []\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalresult(sequence_log,predata_blank):\n",
    "    dataframe = []\n",
    "    count=0\n",
    "    for i in range(len(sequence_log)):\n",
    "        for text in sequence_log[i]:\n",
    "            dataframe.append(text)\n",
    "            count+=1\n",
    "        dataframe.append(\"\")\n",
    "    dftest=pd.DataFrame(dataframe)\n",
    "    final = pd.DataFrame()\n",
    "    final['result'] = predata_blank['x'] + \" \" +dftest[0]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Viterbi\n",
      "(46, 24)\n",
      "(12, 24)\n",
      "(15, 24)\n",
      "(23, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n",
      "/mnt/c/Users/estee/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 24)\n",
      "(32, 24)\n",
      "(6, 24)\n",
      "(29, 24)\n",
      "(24, 24)\n",
      "(18, 24)\n",
      "(14, 24)\n",
      "(27, 24)\n",
      "(23, 24)\n",
      "(22, 24)\n",
      "(16, 24)\n",
      "(40, 24)\n",
      "(28, 24)\n",
      "(14, 24)\n",
      "(31, 24)\n",
      "(31, 24)\n",
      "(33, 24)\n",
      "(35, 24)\n",
      "(25, 24)\n",
      "(30, 24)\n",
      "(35, 24)\n",
      "(20, 24)\n",
      "(45, 24)\n",
      "(35, 24)\n",
      "(31, 24)\n",
      "(24, 24)\n",
      "(22, 24)\n",
      "(27, 24)\n",
      "(20, 24)\n",
      "(24, 24)\n",
      "(12, 24)\n",
      "(10, 24)\n",
      "(27, 24)\n",
      "(27, 24)\n",
      "(15, 24)\n",
      "(11, 24)\n",
      "(30, 24)\n",
      "(38, 24)\n",
      "(18, 24)\n",
      "(25, 24)\n",
      "(7, 24)\n",
      "(40, 24)\n",
      "(24, 24)\n",
      "(39, 24)\n",
      "(10, 24)\n",
      "(37, 24)\n",
      "(30, 24)\n",
      "(34, 24)\n",
      "(39, 24)\n",
      "(25, 24)\n",
      "(23, 24)\n",
      "(32, 24)\n",
      "(3, 24)\n",
      "(16, 24)\n",
      "(29, 24)\n",
      "(25, 24)\n",
      "(26, 24)\n",
      "(29, 24)\n",
      "(14, 24)\n",
      "(23, 24)\n",
      "(34, 24)\n",
      "(35, 24)\n",
      "(43, 24)\n",
      "(34, 24)\n",
      "(20, 24)\n",
      "(25, 24)\n",
      "(11, 24)\n",
      "(7, 24)\n",
      "(16, 24)\n",
      "(38, 24)\n",
      "(9, 24)\n",
      "(19, 24)\n",
      "(18, 24)\n",
      "(21, 24)\n",
      "(34, 24)\n",
      "(38, 24)\n",
      "(11, 24)\n",
      "(30, 24)\n",
      "(14, 24)\n",
      "(20, 24)\n",
      "(19, 24)\n",
      "(15, 24)\n",
      "(31, 24)\n",
      "(11, 24)\n",
      "(27, 24)\n",
      "(24, 24)\n",
      "(10, 24)\n",
      "(20, 24)\n",
      "(32, 24)\n",
      "(33, 24)\n",
      "(5, 24)\n",
      "(24, 24)\n",
      "(18, 24)\n",
      "(20, 24)\n",
      "(38, 24)\n",
      "(33, 24)\n",
      "(29, 24)\n",
      "(38, 24)\n",
      "(14, 24)\n",
      "(33, 24)\n",
      "(35, 24)\n",
      "(18, 24)\n",
      "(33, 24)\n",
      "(23, 24)\n",
      "(25, 24)\n",
      "(28, 24)\n",
      "(16, 24)\n",
      "(21, 24)\n",
      "(19, 24)\n",
      "(28, 24)\n",
      "(3, 24)\n",
      "(41, 24)\n",
      "(37, 24)\n",
      "(35, 24)\n",
      "(30, 24)\n",
      "(13, 24)\n",
      "(20, 24)\n",
      "(27, 24)\n",
      "(16, 24)\n",
      "(33, 24)\n",
      "(37, 24)\n",
      "(34, 24)\n",
      "(16, 24)\n",
      "(14, 24)\n",
      "(17, 24)\n",
      "(25, 24)\n",
      "(16, 24)\n",
      "(32, 24)\n",
      "(6, 24)\n",
      "(20, 24)\n",
      "(17, 24)\n",
      "(32, 24)\n",
      "(41, 24)\n",
      "(18, 24)\n",
      "(39, 24)\n",
      "(16, 24)\n",
      "(28, 24)\n",
      "(31, 24)\n",
      "(41, 24)\n",
      "(55, 24)\n",
      "(20, 24)\n",
      "(29, 24)\n",
      "(28, 24)\n",
      "(5, 24)\n",
      "(40, 24)\n",
      "(23, 24)\n",
      "(35, 24)\n",
      "(33, 24)\n",
      "(51, 24)\n",
      "(35, 24)\n",
      "(15, 24)\n",
      "(43, 24)\n",
      "(14, 24)\n",
      "(16, 24)\n",
      "(8, 24)\n",
      "(19, 24)\n",
      "(28, 24)\n",
      "(19, 24)\n",
      "(38, 24)\n",
      "(25, 24)\n",
      "(29, 24)\n",
      "(30, 24)\n",
      "(11, 24)\n",
      "(23, 24)\n",
      "(18, 24)\n",
      "(16, 24)\n",
      "(40, 24)\n",
      "(22, 24)\n",
      "(14, 24)\n",
      "(14, 24)\n",
      "(26, 24)\n",
      "(36, 24)\n",
      "(22, 24)\n",
      "(32, 24)\n",
      "(19, 24)\n",
      "(7, 24)\n",
      "(23, 24)\n",
      "(32, 24)\n",
      "(30, 24)\n",
      "(12, 24)\n",
      "(9, 24)\n",
      "(29, 24)\n",
      "(42, 24)\n",
      "(10, 24)\n",
      "(28, 24)\n",
      "(42, 24)\n",
      "(38, 24)\n",
      "(24, 24)\n",
      "(22, 24)\n",
      "(16, 24)\n",
      "(20, 24)\n",
      "(34, 24)\n",
      "(22, 24)\n",
      "(56, 24)\n",
      "(19, 24)\n",
      "(30, 24)\n",
      "(23, 24)\n",
      "(6, 24)\n",
      "(27, 24)\n",
      "(27, 24)\n",
      "(7, 24)\n",
      "(16, 24)\n",
      "(13, 24)\n",
      "(21, 24)\n",
      "(28, 24)\n",
      "(38, 24)\n",
      "(26, 24)\n",
      "(15, 24)\n",
      "(27, 24)\n",
      "(44, 24)\n",
      "(72, 24)\n",
      "(23, 24)\n",
      "(19, 24)\n",
      "(47, 24)\n",
      "(48, 24)\n",
      "(29, 24)\n",
      "(44, 24)\n",
      "(7, 24)\n",
      "(27, 24)\n",
      "(26, 24)\n",
      "(5, 24)\n",
      "(31, 24)\n",
      "(30, 24)\n",
      "(24, 24)\n",
      "(26, 24)\n",
      "(59, 24)\n",
      "(42, 24)\n",
      "(30, 24)\n",
      "(18, 24)\n",
      "(21, 24)\n",
      "(12, 24)\n",
      "(56, 24)\n",
      "(3, 24)\n",
      "(17, 24)\n",
      "(14, 24)\n",
      "(21, 24)\n",
      "(53, 24)\n",
      "(37, 24)\n",
      "(40, 24)\n",
      "(13, 24)\n",
      "(41, 24)\n",
      "(31, 24)\n",
      "(42, 24)\n",
      "(34, 24)\n",
      "(20, 24)\n",
      "(28, 24)\n",
      "(42, 24)\n",
      "(28, 24)\n",
      "(19, 24)\n",
      "(15, 24)\n",
      "(53, 24)\n",
      "(7, 24)\n",
      "(40, 24)\n",
      "(12, 24)\n",
      "(24, 24)\n",
      "(22, 24)\n",
      "(18, 24)\n",
      "(19, 24)\n",
      "(25, 24)\n",
      "(30, 24)\n",
      "(17, 24)\n",
      "(32, 24)\n",
      "(31, 24)\n",
      "(19, 24)\n",
      "(19, 24)\n",
      "(24, 24)\n",
      "(15, 24)\n",
      "(44, 24)\n",
      "(29, 24)\n",
      "(19, 24)\n",
      "(12, 24)\n",
      "(18, 24)\n",
      "(7, 24)\n",
      "(7, 24)\n",
      "(16, 24)\n",
      "(25, 24)\n",
      "(43, 24)\n",
      "(33, 24)\n",
      "(22, 24)\n",
      "(18, 24)\n",
      "(27, 24)\n",
      "(20, 24)\n",
      "(14, 24)\n",
      "(30, 24)\n",
      "(19, 24)\n",
      "(38, 24)\n",
      "(33, 24)\n",
      "(32, 24)\n",
      "(32, 24)\n",
      "(27, 24)\n",
      "(21, 24)\n",
      "(4, 24)\n",
      "(13, 24)\n",
      "(44, 24)\n",
      "(25, 24)\n",
      "(28, 24)\n",
      "(23, 24)\n",
      "(30, 24)\n",
      "(37, 24)\n",
      "(21, 24)\n",
      "(30, 24)\n",
      "(17, 24)\n",
      "(18, 24)\n",
      "(32, 24)\n",
      "(20, 24)\n",
      "(26, 24)\n",
      "(30, 24)\n",
      "(39, 24)\n",
      "(11, 24)\n",
      "(34, 24)\n",
      "(19, 24)\n",
      "(33, 24)\n",
      "(27, 24)\n",
      "(21, 24)\n",
      "(27, 24)\n",
      "(34, 24)\n",
      "(19, 24)\n",
      "(23, 24)\n",
      "(29, 24)\n",
      "(20, 24)\n",
      "(19, 24)\n",
      "(14, 24)\n",
      "(21, 24)\n",
      "(27, 24)\n",
      "(31, 24)\n",
      "(25, 24)\n",
      "(19, 24)\n",
      "(29, 24)\n",
      "(45, 24)\n",
      "(29, 24)\n",
      "(10, 24)\n",
      "(31, 24)\n",
      "(28, 24)\n",
      "(9, 24)\n",
      "(21, 24)\n",
      "(15, 24)\n",
      "(32, 24)\n",
      "(42, 24)\n",
      "(23, 24)\n",
      "(32, 24)\n",
      "(26, 24)\n",
      "(12, 24)\n",
      "(21, 24)\n",
      "(22, 24)\n",
      "(41, 24)\n",
      "(34, 24)\n",
      "(37, 24)\n",
      "(25, 24)\n",
      "(19, 24)\n",
      "(62, 24)\n",
      "(32, 24)\n",
      "(21, 24)\n",
      "(23, 24)\n",
      "(41, 24)\n",
      "(19, 24)\n",
      "(29, 24)\n",
      "(18, 24)\n",
      "(17, 24)\n",
      "(25, 24)\n",
      "(8, 24)\n",
      "(22, 24)\n",
      "(29, 24)\n",
      "(12, 24)\n",
      "(27, 24)\n",
      "(37, 24)\n",
      "(23, 24)\n",
      "(18, 24)\n",
      "(55, 24)\n",
      "(36, 24)\n",
      "(24, 24)\n",
      "(28, 24)\n",
      "(16, 24)\n",
      "(27, 24)\n",
      "(16, 24)\n",
      "(21, 24)\n",
      "(42, 24)\n",
      "(14, 24)\n",
      "(23, 24)\n",
      "(26, 24)\n",
      "(41, 24)\n",
      "(20, 24)\n",
      "(26, 24)\n",
      "(24, 24)\n",
      "(18, 24)\n",
      "(28, 24)\n",
      "(23, 24)\n",
      "(15, 24)\n",
      "(8, 24)\n",
      "(7, 24)\n",
      "(18, 24)\n",
      "(54, 24)\n",
      "(17, 24)\n",
      "(17, 24)\n",
      "(39, 24)\n",
      "(11, 24)\n",
      "(19, 24)\n",
      "(9, 24)\n",
      "(24, 24)\n",
      "(22, 24)\n",
      "(31, 24)\n",
      "(14, 24)\n",
      "(34, 24)\n",
      "(15, 24)\n",
      "(10, 24)\n",
      "(21, 24)\n",
      "(18, 24)\n",
      "(33, 24)\n",
      "(20, 24)\n",
      "(46, 24)\n",
      "(21, 24)\n",
      "(19, 24)\n",
      "(14, 24)\n",
      "(13, 24)\n",
      "(34, 24)\n",
      "(30, 24)\n",
      "(40, 24)\n",
      "(19, 24)\n",
      "(23, 24)\n",
      "(30, 24)\n",
      "(25, 24)\n",
      "(30, 24)\n",
      "(17, 24)\n",
      "(17, 24)\n",
      "(17, 24)\n",
      "(9, 24)\n",
      "(37, 24)\n",
      "(12, 24)\n",
      "(20, 24)\n",
      "(17, 24)\n",
      "(36, 24)\n",
      "(24, 24)\n",
      "(3, 24)\n",
      "(27, 24)\n",
      "(19, 24)\n",
      "(41, 24)\n",
      "(21, 24)\n",
      "(12, 24)\n",
      "(35, 24)\n",
      "(31, 24)\n",
      "(14, 24)\n",
      "(56, 24)\n",
      "(25, 24)\n",
      "(49, 24)\n",
      "(24, 24)\n",
      "(21, 24)\n",
      "(12, 24)\n",
      "(40, 24)\n",
      "(11, 24)\n",
      "(26, 24)\n",
      "(43, 24)\n",
      "(44, 24)\n",
      "(13, 24)\n",
      "(40, 24)\n",
      "(25, 24)\n",
      "(21, 24)\n",
      "(16, 24)\n",
      "(26, 24)\n",
      "(14, 24)\n",
      "(30, 24)\n",
      "(19, 24)\n",
      "(3, 24)\n",
      "(68, 24)\n",
      "(27, 24)\n",
      "(28, 24)\n",
      "(32, 24)\n",
      "(24, 24)\n",
      "(42, 24)\n",
      "(39, 24)\n",
      "(21, 24)\n",
      "(27, 24)\n",
      "(35, 24)\n",
      "(31, 24)\n",
      "(25, 24)\n",
      "(11, 24)\n",
      "(15, 24)\n",
      "(24, 24)\n",
      "(16, 24)\n",
      "(12, 24)\n",
      "(12, 24)\n",
      "(25, 24)\n",
      "(10, 24)\n",
      "(20, 24)\n",
      "(7, 24)\n",
      "(5, 24)\n",
      "(35, 24)\n",
      "(3, 24)\n",
      "(16, 24)\n",
      "(16, 24)\n",
      "(21, 24)\n",
      "(20, 24)\n",
      "(20, 24)\n",
      "(25, 24)\n",
      "(15, 24)\n",
      "(30, 24)\n",
      "(16, 24)\n",
      "(21, 24)\n",
      "(19, 24)\n",
      "(44, 24)\n",
      "(40, 24)\n",
      "(3, 24)\n",
      "(41, 24)\n",
      "(19, 24)\n",
      "(25, 24)\n",
      "(18, 24)\n",
      "(18, 24)\n",
      "(15, 24)\n",
      "(23, 24)\n",
      "(32, 24)\n",
      "(21, 24)\n",
      "(27, 24)\n",
      "(24, 24)\n",
      "(30, 24)\n",
      "(15, 24)\n",
      "(27, 24)\n",
      "(24, 24)\n",
      "(7, 24)\n",
      "(20, 24)\n",
      "(21, 24)\n",
      "(28, 24)\n",
      "(39, 24)\n",
      "(18, 24)\n",
      "(33, 24)\n",
      "(20, 24)\n",
      "(32, 24)\n",
      "(27, 24)\n",
      "(19, 24)\n",
      "(28, 24)\n",
      "(38, 24)\n",
      "(25, 24)\n",
      "(23, 24)\n",
      "(20, 24)\n",
      "(18, 24)\n",
      "(16, 24)\n",
      "(18, 24)\n",
      "(28, 24)\n",
      "(13, 24)\n",
      "(13, 24)\n",
      "(19, 24)\n",
      "(44, 24)\n",
      "(29, 24)\n",
      "(24, 24)\n",
      "(15, 24)\n",
      "(51, 24)\n",
      "(31, 24)\n",
      "(24, 24)\n",
      "(12, 24)\n",
      "(20, 24)\n",
      "(5, 24)\n",
      "(47, 24)\n",
      "(34, 24)\n",
      "(8, 24)\n",
      "(4, 24)\n",
      "(7, 24)\n",
      "(13, 24)\n",
      "(31, 24)\n",
      "(35, 24)\n",
      "(16, 24)\n",
      "(22, 24)\n",
      "(36, 24)\n",
      "(13, 24)\n",
      "(14, 24)\n",
      "(14, 24)\n",
      "(11, 24)\n",
      "(11, 24)\n",
      "(11, 24)\n",
      "(15, 24)\n",
      "(18, 24)\n",
      "(28, 24)\n",
      "(61, 24)\n",
      "(19, 24)\n",
      "(30, 24)\n",
      "(10, 24)\n",
      "(17, 24)\n",
      "(21, 24)\n",
      "(32, 24)\n",
      "(25, 24)\n",
      "(14, 24)\n",
      "(32, 24)\n",
      "(33, 24)\n",
      "(16, 24)\n",
      "(9, 24)\n",
      "(12, 24)\n",
      "(14, 24)\n",
      "(24, 24)\n",
      "(9, 24)\n",
      "(45, 24)\n",
      "(17, 24)\n",
      "(17, 24)\n",
      "(27, 24)\n",
      "(24, 24)\n",
      "(22, 24)\n",
      "(17, 24)\n",
      "(19, 24)\n",
      "(41, 24)\n",
      "(42, 24)\n",
      "(10, 24)\n",
      "(20, 24)\n",
      "(34, 24)\n",
      "(30, 24)\n",
      "(36, 24)\n",
      "(37, 24)\n",
      "(18, 24)\n",
      "(17, 24)\n",
      "(40, 24)\n",
      "(14, 24)\n",
      "(24, 24)\n",
      "(27, 24)\n",
      "(35, 24)\n",
      "(21, 24)\n",
      "(18, 24)\n",
      "(20, 24)\n",
      "(36, 24)\n",
      "(30, 24)\n",
      "(13, 24)\n",
      "(24, 24)\n",
      "(41, 24)\n",
      "(6, 24)\n",
      "(30, 24)\n",
      "(35, 24)\n",
      "(19, 24)\n",
      "(25, 24)\n",
      "(21, 24)\n",
      "(18, 24)\n",
      "(43, 24)\n",
      "(16, 24)\n",
      "(21, 24)\n",
      "(23, 24)\n",
      "(38, 24)\n",
      "(24, 24)\n",
      "(13, 24)\n",
      "(18, 24)\n",
      "(15, 24)\n",
      "(37, 24)\n",
      "(37, 24)\n",
      "(36, 24)\n",
      "(13, 24)\n",
      "(17, 24)\n",
      "(7, 24)\n",
      "(45, 24)\n",
      "(27, 24)\n",
      "(10, 24)\n",
      "(18, 24)\n",
      "(10, 24)\n",
      "(33, 24)\n",
      "(29, 24)\n",
      "(27, 24)\n",
      "(17, 24)\n",
      "(31, 24)\n",
      "(19, 24)\n",
      "(53, 24)\n",
      "(9, 24)\n",
      "(37, 24)\n",
      "(18, 24)\n",
      "(12, 24)\n",
      "(32, 24)\n",
      "(40, 24)\n",
      "(7, 24)\n",
      "(20, 24)\n",
      "(19, 24)\n",
      "(18, 24)\n",
      "(18, 24)\n",
      "(25, 24)\n",
      "(53, 24)\n",
      "(12, 24)\n",
      "(22, 24)\n",
      "(20, 24)\n",
      "(36, 24)\n",
      "(31, 24)\n",
      "(17, 24)\n",
      "(25, 24)\n",
      "(30, 24)\n",
      "(26, 24)\n",
      "(28, 24)\n",
      "(28, 24)\n",
      "(16, 24)\n",
      "(20, 24)\n",
      "(22, 24)\n",
      "(22, 24)\n",
      "(36, 24)\n",
      "(31, 24)\n",
      "(11, 24)\n",
      "(49, 24)\n",
      "(37, 24)\n",
      "(19, 24)\n",
      "(19, 24)\n",
      "(42, 24)\n",
      "(35, 24)\n",
      "(23, 24)\n",
      "(31, 24)\n",
      "(11, 24)\n",
      "(18, 24)\n",
      "(19, 24)\n",
      "(30, 24)\n",
      "(25, 24)\n",
      "(23, 24)\n",
      "(34, 24)\n",
      "(20, 24)\n",
      "(29, 24)\n",
      "(37, 24)\n",
      "(22, 24)\n",
      "(17, 24)\n",
      "(33, 24)\n",
      "(8, 24)\n",
      "(14, 24)\n",
      "(30, 24)\n",
      "(16, 24)\n",
      "(12, 24)\n",
      "(11, 24)\n",
      "(9, 24)\n",
      "(23, 24)\n",
      "(7, 24)\n",
      "(15, 24)\n",
      "(13, 24)\n",
      "(27, 24)\n",
      "(20, 24)\n",
      "(17, 24)\n",
      "(29, 24)\n",
      "(22, 24)\n",
      "(26, 24)\n",
      "(29, 24)\n",
      "(23, 24)\n",
      "(23, 24)\n",
      "(37, 24)\n",
      "(20, 24)\n",
      "(16, 24)\n",
      "(22, 24)\n",
      "(11, 24)\n",
      "(7, 24)\n",
      "(40, 24)\n",
      "(25, 24)\n",
      "(44, 24)\n",
      "(42, 24)\n",
      "(37, 24)\n",
      "(23, 24)\n",
      "(21, 24)\n",
      "(8, 24)\n",
      "(26, 24)\n",
      "(9, 24)\n",
      "(22, 24)\n",
      "(30, 24)\n",
      "(31, 24)\n",
      "(17, 24)\n",
      "(32, 24)\n",
      "(32, 24)\n",
      "(30, 24)\n",
      "(8, 24)\n",
      "(28, 24)\n",
      "(40, 24)\n",
      "(37, 24)\n",
      "(25, 24)\n",
      "(29, 24)\n",
      "(45, 24)\n",
      "(24, 24)\n",
      "(30, 24)\n",
      "(19, 24)\n",
      "(12, 24)\n",
      "(10, 24)\n",
      "(36, 24)\n",
      "(7, 24)\n",
      "(32, 24)\n",
      "(12, 24)\n",
      "(24, 24)\n",
      "(18, 24)\n",
      "(30, 24)\n",
      "(41, 24)\n",
      "(11, 24)\n",
      "(39, 24)\n",
      "(25, 24)\n",
      "(16, 24)\n",
      "(17, 24)\n",
      "(24, 24)\n",
      "(18, 24)\n",
      "(46, 24)\n",
      "(11, 24)\n",
      "(21, 24)\n",
      "(18, 24)\n",
      "(26, 24)\n",
      "(36, 24)\n",
      "(33, 24)\n",
      "(43, 24)\n",
      "(31, 24)\n",
      "(32, 24)\n",
      "(10, 24)\n",
      "(14, 24)\n",
      "(30, 24)\n",
      "(64, 24)\n",
      "(10, 24)\n",
      "(14, 24)\n",
      "(29, 24)\n",
      "(16, 24)\n",
      "(26, 24)\n",
      "(29, 24)\n",
      "(3, 24)\n",
      "(38, 24)\n",
      "(28, 24)\n",
      "(26, 24)\n",
      "(22, 24)\n",
      "(21, 24)\n",
      "(44, 24)\n",
      "(32, 24)\n",
      "(34, 24)\n",
      "(12, 24)\n",
      "(40, 24)\n",
      "(12, 24)\n",
      "(13, 24)\n",
      "(10, 24)\n",
      "(28, 24)\n",
      "(14, 24)\n",
      "(10, 24)\n",
      "(5, 24)\n",
      "(37, 24)\n",
      "(23, 24)\n",
      "(28, 24)\n",
      "(59, 24)\n",
      "(30, 24)\n",
      "(14, 24)\n",
      "(37, 24)\n",
      "(51, 24)\n",
      "(32, 24)\n",
      "(29, 24)\n",
      "(49, 24)\n",
      "(37, 24)\n",
      "(53, 24)\n",
      "(16, 24)\n",
      "(23, 24)\n",
      "(29, 24)\n",
      "(30, 24)\n",
      "(40, 24)\n",
      "(21, 24)\n",
      "(26, 24)\n",
      "(25, 24)\n",
      "(34, 24)\n",
      "(6, 24)\n",
      "(24, 24)\n",
      "(5, 24)\n",
      "(20, 24)\n",
      "(22, 24)\n",
      "(27, 24)\n",
      "(18, 24)\n",
      "(33, 24)\n",
      "(21, 24)\n",
      "(20, 24)\n",
      "(22, 24)\n",
      "(10, 24)\n",
      "(42, 24)\n",
      "(29, 24)\n",
      "(25, 24)\n",
      "(31, 24)\n",
      "(26, 24)\n",
      "(31, 24)\n",
      "(29, 24)\n",
      "(46, 24)\n",
      "(52, 24)\n",
      "(26, 24)\n",
      "(13, 24)\n",
      "(23, 24)\n",
      "(56, 24)\n",
      "(31, 24)\n",
      "(30, 24)\n",
      "(8, 24)\n",
      "(23, 24)\n",
      "(12, 24)\n",
      "(28, 24)\n",
      "(36, 24)\n",
      "(30, 24)\n",
      "(3, 24)\n",
      "(20, 24)\n",
      "(26, 24)\n",
      "(14, 24)\n",
      "(14, 24)\n",
      "(31, 24)\n",
      "(19, 24)\n",
      "(9, 24)\n",
      "(23, 24)\n",
      "(30, 24)\n",
      "(32, 24)\n",
      "(20, 24)\n",
      "(24, 24)\n",
      "(33, 24)\n",
      "(14, 24)\n",
      "(23, 24)\n",
      "(7, 24)\n",
      "(33, 24)\n",
      "(11, 24)\n",
      "(21, 24)\n",
      "(17, 24)\n",
      "(32, 24)\n",
      "(19, 24)\n",
      "(16, 24)\n",
      "(12, 24)\n",
      "(27, 24)\n",
      "(6, 24)\n",
      "(31, 24)\n",
      "(23, 24)\n",
      "(24, 24)\n",
      "(24, 24)\n",
      "(64, 24)\n",
      "(34, 24)\n",
      "(9, 24)\n",
      "(20, 24)\n",
      "(8, 24)\n",
      "(30, 24)\n",
      "(24, 24)\n",
      "(37, 24)\n",
      "(17, 24)\n",
      "(12, 24)\n",
      "(24, 24)\n",
      "(19, 24)\n",
      "(13, 24)\n",
      "(12, 24)\n",
      "(24, 24)\n",
      "(30, 24)\n",
      "(28, 24)\n",
      "(42, 24)\n",
      "(24, 24)\n",
      "(27, 24)\n",
      "(29, 24)\n",
      "(42, 24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 24)\n",
      "(15, 24)\n",
      "(25, 24)\n",
      "(12, 24)\n",
      "(30, 24)\n",
      "(9, 24)\n",
      "(28, 24)\n",
      "(8, 24)\n",
      "(26, 24)\n",
      "(29, 24)\n",
      "(25, 24)\n",
      "(28, 24)\n",
      "(31, 24)\n",
      "(27, 24)\n",
      "(42, 24)\n",
      "(16, 24)\n",
      "(49, 24)\n",
      "(26, 24)\n",
      "(29, 24)\n",
      "(18, 24)\n",
      "(30, 24)\n",
      "(34, 24)\n",
      "(32, 24)\n",
      "(32, 24)\n",
      "(17, 24)\n",
      "(19, 24)\n",
      "(19, 24)\n",
      "(38, 24)\n",
      "(18, 24)\n",
      "(7, 24)\n",
      "(36, 24)\n",
      "(39, 24)\n",
      "(13, 24)\n",
      "(36, 24)\n",
      "(24, 24)\n",
      "(35, 24)\n",
      "(34, 24)\n",
      "(6, 24)\n",
      "(9, 24)\n",
      "(31, 24)\n",
      "(13, 24)\n",
      "(23, 24)\n",
      "(29, 24)\n",
      "(32, 24)\n",
      "(14, 24)\n",
      "(31, 24)\n",
      "(25, 24)\n",
      "(17, 24)\n",
      "(38, 24)\n",
      "(19, 24)\n",
      "(22, 24)\n",
      "(26, 24)\n",
      "(30, 24)\n",
      "(37, 24)\n",
      "(23, 24)\n",
      "(22, 24)\n",
      "(20, 24)\n",
      "(18, 24)\n",
      "(50, 24)\n",
      "(26, 24)\n",
      "(15, 24)\n",
      "(4, 24)\n",
      "(20, 24)\n",
      "(54, 24)\n",
      "(27, 24)\n",
      "(53, 24)\n",
      "(34, 24)\n",
      "(16, 24)\n",
      "(26, 24)\n",
      "(32, 24)\n",
      "(15, 24)\n",
      "(28, 24)\n",
      "(33, 24)\n",
      "(11, 24)\n",
      "(24, 24)\n",
      "(25, 24)\n",
      "(21, 24)\n",
      "(11, 24)\n",
      "(33, 24)\n",
      "(8, 24)\n",
      "(29, 24)\n",
      "(21, 24)\n",
      "(12, 24)\n",
      "(25, 24)\n",
      "(15, 24)\n",
      "(27, 24)\n",
      "(26, 24)\n",
      "(18, 24)\n",
      "(31, 24)\n",
      "(22, 24)\n",
      "(32, 24)\n",
      "(16, 24)\n",
      "(12, 24)\n",
      "(23, 24)\n",
      "(37, 24)\n",
      "(45, 24)\n",
      "(14, 24)\n",
      "(25, 24)\n",
      "(25, 24)\n",
      "(14, 24)\n",
      "(4, 24)\n",
      "(11, 24)\n",
      "(28, 24)\n",
      "(13, 24)\n",
      "(13, 24)\n",
      "(28, 24)\n",
      "(39, 24)\n",
      "(27, 24)\n",
      "(23, 24)\n",
      "(16, 24)\n",
      "(45, 24)\n",
      "(43, 24)\n",
      "(22, 24)\n",
      "(11, 24)\n",
      "(50, 24)\n",
      "(7, 24)\n",
      "(26, 24)\n",
      "(27, 24)\n",
      "(29, 24)\n",
      "(8, 24)\n",
      "(16, 24)\n",
      "(49, 24)\n",
      "(25, 24)\n",
      "(6, 24)\n",
      "(33, 24)\n",
      "(24, 24)\n",
      "(25, 24)\n",
      "(49, 24)\n",
      "(32, 24)\n",
      "(33, 24)\n",
      "(23, 24)\n",
      "(35, 24)\n",
      "(17, 24)\n",
      "(23, 24)\n",
      "(28, 24)\n",
      "(13, 24)\n",
      "(15, 24)\n",
      "(22, 24)\n",
      "(28, 24)\n",
      "(20, 24)\n",
      "(21, 24)\n",
      "(26, 24)\n",
      "(49, 24)\n",
      "(13, 24)\n",
      "(17, 24)\n",
      "(17, 24)\n",
      "(9, 24)\n",
      "(31, 24)\n",
      "(22, 24)\n",
      "(29, 24)\n",
      "(33, 24)\n",
      "(33, 24)\n",
      "(30, 24)\n",
      "(25, 24)\n",
      "(41, 24)\n",
      "(15, 24)\n",
      "(10, 24)\n",
      "(40, 24)\n",
      "(40, 24)\n",
      "(34, 24)\n",
      "(46, 24)\n",
      "(37, 24)\n",
      "(53, 24)\n",
      "(38, 24)\n",
      "(62, 24)\n",
      "(24, 24)\n",
      "(13, 24)\n",
      "(27, 24)\n",
      "(28, 24)\n",
      "(28, 24)\n",
      "(26, 24)\n",
      "(8, 24)\n",
      "Time taken for Viterbi and Backtrack 220.7657778263092\n",
      "Writing the final result to dev.p3.out...\n",
      "Finished Writing.\n"
     ]
    }
   ],
   "source": [
    "data_folders = [\"AL\", \"EN\",\"CN\",\"SG\"]\n",
    "for x in [\"EN\"]:\n",
    "#     print(\"Performing sentiment analysis for data folder \", x)\n",
    "    train_data = \"./data/{}/train\".format(x)\n",
    "    test_data = \"./data/{}/dev.in\".format(x)\n",
    "#     test_result = \"./data/{}/dev.out\".format(x)\n",
    "    \n",
    "#     predata = preprocess_training(train_data)\n",
    "#     countData=uniqueCount(predata,k,replaceWord)\n",
    "#     emissiondf = emissionCalcu(countData)\n",
    "#     emission_dict = emissiondf[1]\n",
    "#     xy_pred_dic = xyPrediction(emissiondf[0])\n",
    "#     testdf_unprocess = pd.read_csv(test_data, sep='/n', delimiter=None, names=['x'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "#     testdf = preprocess_test(test_data,k)\n",
    "    \n",
    "#     testresultdf = pd.read_csv(test_result, sep='/n', delimiter=None, names=['original'],index_col=False, engine=\"python\")\n",
    "#     new = testresultdf[\"original\"].str.split(\" \", n=1,expand=True) \n",
    "\n",
    "#     # making separate first name column from new data frame \n",
    "#     testresultdf[\"x\"]= new[0] \n",
    "\n",
    "#     # making separate last name column from new data frame \n",
    "#     testresultdf[\"y\"]= new[1]\n",
    "#     final = pd.DataFrame()\n",
    "    \n",
    "#     final['result'] = testdf['modified'] + ' ' + testdf['predict_label']\n",
    "# #     print(final.head(3))\n",
    "    \n",
    "#     print(\"Writing the final result to dev.p2..out...\")\n",
    "#     f = open('./output/{}/dev.p2.out'.format(x) ,'w')\n",
    "#     for word in final['result']:\n",
    "#         f.write(word + '\\n')\n",
    "#     f.close()\n",
    "    \n",
    "# ##############################PART 3########################################################\n",
    "    transition_dic, subseq_count, y_count = transitionPara(train_data)\n",
    "    predata_blank=preprocess_training_blank_row(train_data)\n",
    "    node = list(y_count.keys())\n",
    "#     print(testdf_unprocess)\n",
    "    testdf_unprocess = pd.read_csv(test_data, sep='/n', delimiter=None, names=['x'],index_col=False,skip_blank_lines=False, engine=\"python\")\n",
    "    lines= sentenceList(testdf_unprocess)\n",
    "    \n",
    "    nodes = node\n",
    "    log_array =[]\n",
    "    sequence_log=[]\n",
    "\n",
    "    \n",
    "    print(\"Performing Viterbi\")\n",
    "    start = time.time()\n",
    "    for i in range(len(lines)):\n",
    "        viterbioutput=viterbi(lines[i])\n",
    "        log_array.append(viterbioutput)\n",
    "        sequence_log.append(viterbi_backtrack(viterbioutput))\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Time taken for Viterbi and Backtrack\", end - start)\n",
    "#     print(sequence_log)\n",
    "    \n",
    "    result = finalresult(sequence_log,testdf_unprocess)\n",
    "#     print(result)\n",
    "    \n",
    "    print(\"Writing the final result to dev.p3.out...\")\n",
    "#     f = open('./dev.p3.out'.format(x) ,'w')\n",
    "    f = open('./output/{}/dev.p3.out'.format(x) ,'w')\n",
    "    for word in result['result']:\n",
    "        if pd.isnull(word) == False:\n",
    "            f.write(word + '\\n')\n",
    "        else:\n",
    "            f.write(\"\" +\"\\n\")\n",
    "    f.close()\n",
    "    print(\"Finished Writing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HBO B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>has START</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>close B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>to START</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24 B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28319 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           result\n",
       "0        HBO B-NP\n",
       "1       has START\n",
       "2      close B-NP\n",
       "3        to START\n",
       "4         24 B-NP\n",
       "...           ...\n",
       "28314         NaN\n",
       "28315         NaN\n",
       "28316         NaN\n",
       "28317         NaN\n",
       "28318         NaN\n",
       "\n",
       "[28319 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
